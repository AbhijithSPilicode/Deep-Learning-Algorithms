{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee061413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON file is something like a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b77f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is used when key-value pairs of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a36b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JavaScript Object Notation - JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4680d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7d34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\user\\\\Downloads\\\\intents.json\") as file:\n",
    "    data=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "306a6d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n",
       "   'responses': ['Hello, thanks for visiting',\n",
       "    'Good to see you again',\n",
       "    'Hi there, how can I help?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later, thanks for visiting',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
       "  {'tag': 'hours',\n",
       "   'patterns': ['What hours are you open?',\n",
       "    'What are your hours?',\n",
       "    'When are you open?'],\n",
       "   'responses': [\"We're open every day 9am-9pm\",\n",
       "    'Our hours are 9am-9pm every day']},\n",
       "  {'tag': 'location',\n",
       "   'patterns': ['What is your location?',\n",
       "    'Where are you located?',\n",
       "    'What is your address?',\n",
       "    'Where is your restaurant situated?'],\n",
       "   'responses': ['We are on the intersection of London Alley and Bridge Avenue.',\n",
       "    'We are situated at the intersection of London Alley and Bridge Avenue',\n",
       "    'Our Address is: 1000 Bridge Avenue, London EC3N 4AJ, UK']},\n",
       "  {'tag': 'payments',\n",
       "   'patterns': ['Do you take credit cards?',\n",
       "    'Do you accept Mastercard?',\n",
       "    'Are you cash only?'],\n",
       "   'responses': ['We accept VISA, Mastercard and AMEX',\n",
       "    'We accept most major credit cards']},\n",
       "  {'tag': 'todaysmenu',\n",
       "   'patterns': ['What is your menu for today?',\n",
       "    'What are you serving today?',\n",
       "    \"What is today's special?\"],\n",
       "   'responses': [\"Today's special is Chicken Tikka\",\n",
       "    'Our speciality for today is Chicken Tikka']},\n",
       "  {'tag': 'deliveryoption',\n",
       "   'patterns': ['Do you provide home delivery?',\n",
       "    'Do you deliver the food?',\n",
       "    'What are the home delivery options?'],\n",
       "   'responses': ['Yes, we provide home delivery through UBER Eats and Zomato?',\n",
       "    'We have home delivery options through UBER Eats and Zomato'],\n",
       "   'context_set': 'food'},\n",
       "  {'tag': 'menu',\n",
       "   'patterns': ['What is your Menu?',\n",
       "    'What are the main course options?',\n",
       "    'Can you tell me the most delicious dish from the menu?',\n",
       "    \"What is the today's special?\"],\n",
       "   'responses': ['You can visit www.mymenu.com for menu options',\n",
       "    'You can check out the food menu at www.mymenu.com',\n",
       "    'You can check various delicacies given in the food menu at www.mymenu.com'],\n",
       "   'context_filter': 'food'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95e37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf301a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41487d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db81b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'today', \"'s\", 'special', '?']\n",
      "\n",
      "\n",
      "['Hi', 'How', 'are', 'you', 'Is', 'anyone', 'there', '?', 'Hello', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'What', 'hours', 'are', 'you', 'open', '?', 'What', 'are', 'your', 'hours', '?', 'When', 'are', 'you', 'open', '?', 'What', 'is', 'your', 'location', '?', 'Where', 'are', 'you', 'located', '?', 'What', 'is', 'your', 'address', '?', 'Where', 'is', 'your', 'restaurant', 'situated', '?', 'Do', 'you', 'take', 'credit', 'cards', '?', 'Do', 'you', 'accept', 'Mastercard', '?', 'Are', 'you', 'cash', 'only', '?', 'What', 'is', 'your', 'menu', 'for', 'today', '?', 'What', 'are', 'you', 'serving', 'today', '?', 'What', 'is', 'today', \"'s\", 'special', '?', 'Do', 'you', 'provide', 'home', 'delivery', '?', 'Do', 'you', 'deliver', 'the', 'food', '?', 'What', 'are', 'the', 'home', 'delivery', 'options', '?', 'What', 'is', 'your', 'Menu', '?', 'What', 'are', 'the', 'main', 'course', 'options', '?', 'Can', 'you', 'tell', 'me', 'the', 'most', 'delicious', 'dish', 'from', 'the', 'menu', '?', 'What', 'is', 'the', 'today', \"'s\", 'special', '?']\n",
      "\n",
      "\n",
      "[['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Bye'], ['See', 'you', 'later'], ['Goodbye'], ['Thanks'], ['Thank', 'you'], ['That', \"'s\", 'helpful'], ['What', 'hours', 'are', 'you', 'open', '?'], ['What', 'are', 'your', 'hours', '?'], ['When', 'are', 'you', 'open', '?'], ['What', 'is', 'your', 'location', '?'], ['Where', 'are', 'you', 'located', '?'], ['What', 'is', 'your', 'address', '?'], ['Where', 'is', 'your', 'restaurant', 'situated', '?'], ['Do', 'you', 'take', 'credit', 'cards', '?'], ['Do', 'you', 'accept', 'Mastercard', '?'], ['Are', 'you', 'cash', 'only', '?'], ['What', 'is', 'your', 'menu', 'for', 'today', '?'], ['What', 'are', 'you', 'serving', 'today', '?'], ['What', 'is', 'today', \"'s\", 'special', '?'], ['Do', 'you', 'provide', 'home', 'delivery', '?'], ['Do', 'you', 'deliver', 'the', 'food', '?'], ['What', 'are', 'the', 'home', 'delivery', 'options', '?'], ['What', 'is', 'your', 'Menu', '?'], ['What', 'are', 'the', 'main', 'course', 'options', '?'], ['Can', 'you', 'tell', 'me', 'the', 'most', 'delicious', 'dish', 'from', 'the', 'menu', '?'], ['What', 'is', 'the', 'today', \"'s\", 'special', '?']]\n",
      "\n",
      "\n",
      "['greeting', 'greeting', 'greeting', 'greeting', 'greeting', 'goodbye', 'goodbye', 'goodbye', 'thanks', 'thanks', 'thanks', 'hours', 'hours', 'hours', 'location', 'location', 'location', 'location', 'payments', 'payments', 'payments', 'todaysmenu', 'todaysmenu', 'todaysmenu', 'deliveryoption', 'deliveryoption', 'deliveryoption', 'menu', 'menu', 'menu', 'menu']\n",
      "\n",
      "\n",
      "['greeting', 'goodbye', 'thanks', 'hours', 'location', 'payments', 'todaysmenu', 'deliveryoption', 'menu']\n"
     ]
    }
   ],
   "source": [
    "#Extract Data\n",
    "words=[]\n",
    "labels=[]\n",
    "docs_x=[]\n",
    "docs_y=[]\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        wrds=nltk.word_tokenize(pattern)\n",
    "        words.extend(wrds) #extend is used to add multiple value at a time\n",
    "        docs_x.append(wrds)\n",
    "        docs_y.append(intent[\"tag\"])\n",
    "        #unique tags\n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "        \n",
    "        \n",
    "#just to check results   \n",
    "print(wrds)\n",
    "print(\"\\n\")\n",
    "print(words)\n",
    "print(\"\\n\")\n",
    "print(docs_x)\n",
    "print(\"\\n\")\n",
    "print(docs_y)\n",
    "print(\"\\n\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166610cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'how',\n",
       " 'ar',\n",
       " 'you',\n",
       " 'is',\n",
       " 'anyon',\n",
       " 'ther',\n",
       " 'hello',\n",
       " 'good',\n",
       " 'day',\n",
       " 'bye',\n",
       " 'see',\n",
       " 'you',\n",
       " 'lat',\n",
       " 'goodby',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'help',\n",
       " 'what',\n",
       " 'hour',\n",
       " 'ar',\n",
       " 'you',\n",
       " 'op',\n",
       " 'what',\n",
       " 'ar',\n",
       " 'yo',\n",
       " 'hour',\n",
       " 'when',\n",
       " 'ar',\n",
       " 'you',\n",
       " 'op',\n",
       " 'what',\n",
       " 'is',\n",
       " 'yo',\n",
       " 'loc',\n",
       " 'wher',\n",
       " 'ar',\n",
       " 'you',\n",
       " 'loc',\n",
       " 'what',\n",
       " 'is',\n",
       " 'yo',\n",
       " 'address',\n",
       " 'wher',\n",
       " 'is',\n",
       " 'yo',\n",
       " 'resta',\n",
       " 'situ',\n",
       " 'do',\n",
       " 'you',\n",
       " 'tak',\n",
       " 'credit',\n",
       " 'card',\n",
       " 'do',\n",
       " 'you',\n",
       " 'acceiv',\n",
       " 'mastercard',\n",
       " 'ar',\n",
       " 'you',\n",
       " 'cash',\n",
       " 'on',\n",
       " 'what',\n",
       " 'is',\n",
       " 'yo',\n",
       " 'menu',\n",
       " 'for',\n",
       " 'today',\n",
       " 'what',\n",
       " 'ar',\n",
       " 'you',\n",
       " 'serv',\n",
       " 'today',\n",
       " 'what',\n",
       " 'is',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'spec',\n",
       " 'do',\n",
       " 'you',\n",
       " 'provid',\n",
       " 'hom',\n",
       " 'delivery',\n",
       " 'do',\n",
       " 'you',\n",
       " 'del',\n",
       " 'the',\n",
       " 'food',\n",
       " 'what',\n",
       " 'ar',\n",
       " 'the',\n",
       " 'hom',\n",
       " 'delivery',\n",
       " 'opt',\n",
       " 'what',\n",
       " 'is',\n",
       " 'yo',\n",
       " 'menu',\n",
       " 'what',\n",
       " 'ar',\n",
       " 'the',\n",
       " 'main',\n",
       " 'cours',\n",
       " 'opt',\n",
       " 'can',\n",
       " 'you',\n",
       " 'tel',\n",
       " 'me',\n",
       " 'the',\n",
       " 'most',\n",
       " 'delicy',\n",
       " 'dish',\n",
       " 'from',\n",
       " 'the',\n",
       " 'menu',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'spec']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "words=[stemmer.stem(w.lower()) for w in words if w!='?'] #removing ?\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd34df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=sorted(list(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3360db",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535f31cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s\",\n",
       " 'acceiv',\n",
       " 'address',\n",
       " 'anyon',\n",
       " 'ar',\n",
       " 'bye',\n",
       " 'can',\n",
       " 'card',\n",
       " 'cash',\n",
       " 'cours',\n",
       " 'credit',\n",
       " 'day',\n",
       " 'del',\n",
       " 'delicy',\n",
       " 'delivery',\n",
       " 'dish',\n",
       " 'do',\n",
       " 'food',\n",
       " 'for',\n",
       " 'from',\n",
       " 'good',\n",
       " 'goodby',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hi',\n",
       " 'hom',\n",
       " 'hour',\n",
       " 'how',\n",
       " 'is',\n",
       " 'lat',\n",
       " 'loc',\n",
       " 'main',\n",
       " 'mastercard',\n",
       " 'me',\n",
       " 'menu',\n",
       " 'most',\n",
       " 'on',\n",
       " 'op',\n",
       " 'opt',\n",
       " 'provid',\n",
       " 'resta',\n",
       " 'see',\n",
       " 'serv',\n",
       " 'situ',\n",
       " 'spec',\n",
       " 'tak',\n",
       " 'tel',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'the',\n",
       " 'ther',\n",
       " 'today',\n",
       " 'what',\n",
       " 'when',\n",
       " 'wher',\n",
       " 'yo',\n",
       " 'you']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72b79cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BAG of words,it will represent each word with number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acdd92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=[]\n",
    "output=[]\n",
    "output_empty=[0 for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fccf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dca037ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi']\n",
      "stemmed ['hi']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "['How', 'are', 'you']\n",
      "stemmed ['how', 'ar', 'you']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "['Is', 'anyone', 'there', '?']\n",
      "stemmed ['is', 'anyon', 'ther', '?']\n",
      "Bag [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "['Hello']\n",
      "stemmed ['hello']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "['Good', 'day']\n",
      "stemmed ['good', 'day']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "['Bye']\n",
      "stemmed ['bye']\n",
      "Bag [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "['See', 'you', 'later']\n",
      "stemmed ['see', 'you', 'lat']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Goodbye']\n",
      "stemmed ['goodby']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Thanks']\n",
      "stemmed ['thank']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "['Thank', 'you']\n",
      "stemmed ['thank', 'you']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "['That', \"'s\", 'helpful']\n",
      "stemmed ['that', \"'s\", 'help']\n",
      "Bag [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "['What', 'hours', 'are', 'you', 'open', '?']\n",
      "stemmed ['what', 'hour', 'ar', 'you', 'op', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "['What', 'are', 'your', 'hours', '?']\n",
      "stemmed ['what', 'ar', 'yo', 'hour', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "['When', 'are', 'you', 'open', '?']\n",
      "stemmed ['when', 'ar', 'you', 'op', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "['What', 'is', 'your', 'location', '?']\n",
      "stemmed ['what', 'is', 'yo', 'loc', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "['Where', 'are', 'you', 'located', '?']\n",
      "stemmed ['wher', 'ar', 'you', 'loc', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "['What', 'is', 'your', 'address', '?']\n",
      "stemmed ['what', 'is', 'yo', 'address', '?']\n",
      "Bag [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "['Where', 'is', 'your', 'restaurant', 'situated', '?']\n",
      "stemmed ['wher', 'is', 'yo', 'resta', 'situ', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "['Do', 'you', 'take', 'credit', 'cards', '?']\n",
      "stemmed ['do', 'you', 'tak', 'credit', 'card', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "['Do', 'you', 'accept', 'Mastercard', '?']\n",
      "stemmed ['do', 'you', 'acceiv', 'mastercard', '?']\n",
      "Bag [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "['Are', 'you', 'cash', 'only', '?']\n",
      "stemmed ['ar', 'you', 'cash', 'on', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "['What', 'is', 'your', 'menu', 'for', 'today', '?']\n",
      "stemmed ['what', 'is', 'yo', 'menu', 'for', 'today', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "['What', 'are', 'you', 'serving', 'today', '?']\n",
      "stemmed ['what', 'ar', 'you', 'serv', 'today', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "['What', 'is', 'today', \"'s\", 'special', '?']\n",
      "stemmed ['what', 'is', 'today', \"'s\", 'spec', '?']\n",
      "Bag [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "['Do', 'you', 'provide', 'home', 'delivery', '?']\n",
      "stemmed ['do', 'you', 'provid', 'hom', 'delivery', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Do', 'you', 'deliver', 'the', 'food', '?']\n",
      "stemmed ['do', 'you', 'del', 'the', 'food', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['What', 'are', 'the', 'home', 'delivery', 'options', '?']\n",
      "stemmed ['what', 'ar', 'the', 'hom', 'delivery', 'opt', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['What', 'is', 'your', 'Menu', '?']\n",
      "stemmed ['what', 'is', 'yo', 'menu', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "['What', 'are', 'the', 'main', 'course', 'options', '?']\n",
      "stemmed ['what', 'ar', 'the', 'main', 'cours', 'opt', '?']\n",
      "Bag [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "['Can', 'you', 'tell', 'me', 'the', 'most', 'delicious', 'dish', 'from', 'the', 'menu', '?']\n",
      "stemmed ['can', 'you', 'tel', 'me', 'the', 'most', 'delicy', 'dish', 'from', 'the', 'menu', '?']\n",
      "Bag [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "['What', 'is', 'the', 'today', \"'s\", 'special', '?']\n",
      "stemmed ['what', 'is', 'the', 'today', \"'s\", 'spec', '?']\n",
      "Bag [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for x,doc in enumerate(docs_x): #enumerate is used to get the element along with the index\n",
    "    bag=[]\n",
    "    wrds=[stemmer.stem(w.lower()) for w in doc]\n",
    "    print(doc)\n",
    "    print(\"stemmed\",wrds)\n",
    "    for i in words:\n",
    "        if i in wrds:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    print(\"Bag\",bag)\n",
    "    output_row=output_empty[:] #type of tag\n",
    "    output_row[labels.index(docs_y[x])]=1 #label.index(\"menu\")=1\n",
    "    print(output_row)\n",
    "    training.append(bag)\n",
    "    output.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56dd7c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deliveryoption',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'hours',\n",
       " 'location',\n",
       " 'menu',\n",
       " 'payments',\n",
       " 'thanks',\n",
       " 'todaysmenu']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c611ef8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7191c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output #what type of tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ccf9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cc9c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=np.array(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e82056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=np.array(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e01c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\pythomopencv\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f4650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "051316cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d75d314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b33e40fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1214b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\pythomopencv\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "net=tflearn.input_data(shape=[None,len(training[0])])\n",
    "net=tflearn.fully_connected(net,8)\n",
    "net=tflearn.fully_connected(net,8) #hiddenlayer\n",
    "net=tflearn.fully_connected(net,len(output[0]),activation='softmax') #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37d30860",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=tflearn.regression(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "322f53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92124dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: X3399T\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 31\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.093s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 31/31\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m1.97750\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 002 | loss: 1.97750 - acc: 0.1161 -- iter: 31/31\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m2.15711\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 003 | loss: 2.15711 - acc: 0.1267 -- iter: 31/31\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m2.18690\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 004 | loss: 2.18690 - acc: 0.1284 -- iter: 31/31\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m2.19364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 005 | loss: 2.19364 - acc: 0.1735 -- iter: 31/31\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m2.19544\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 006 | loss: 2.19544 - acc: 0.1657 -- iter: 31/31\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m2.19591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 007 | loss: 2.19591 - acc: 0.1630 -- iter: 31/31\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m2.19598\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 008 | loss: 2.19598 - acc: 0.1621 -- iter: 31/31\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m2.19589\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 009 | loss: 2.19589 - acc: 0.1616 -- iter: 31/31\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m2.19584\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 010 | loss: 2.19584 - acc: 0.1615 -- iter: 31/31\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m2.19562\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 011 | loss: 2.19562 - acc: 0.1614 -- iter: 31/31\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m2.19542\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 012 | loss: 2.19542 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m2.19521\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 013 | loss: 2.19521 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m2.19500\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 014 | loss: 2.19500 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m2.19479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 015 | loss: 2.19479 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m2.19457\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 016 | loss: 2.19457 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m2.19434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 017 | loss: 2.19434 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m2.19410\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 018 | loss: 2.19410 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m2.19385\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 019 | loss: 2.19385 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m2.19360\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 020 | loss: 2.19360 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m2.19333\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 021 | loss: 2.19333 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m2.19304\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 022 | loss: 2.19304 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m2.19274\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 023 | loss: 2.19274 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m2.19243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 024 | loss: 2.19243 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m2.19245\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 025 | loss: 2.19245 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m2.19201\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 026 | loss: 2.19201 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m2.19158\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 027 | loss: 2.19158 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m2.19116\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 028 | loss: 2.19116 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m2.19072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 029 | loss: 2.19072 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m2.19027\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 030 | loss: 2.19027 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m2.18980\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 031 | loss: 2.18980 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m2.18930\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 032 | loss: 2.18930 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m2.18878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 033 | loss: 2.18878 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m2.18822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 034 | loss: 2.18822 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m2.18763\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 035 | loss: 2.18763 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m2.18865\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 036 | loss: 2.18865 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m2.18768\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 037 | loss: 2.18768 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m2.18676\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 038 | loss: 2.18676 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m2.18586\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 039 | loss: 2.18586 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m2.18496\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 040 | loss: 2.18496 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m2.18406\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 041 | loss: 2.18406 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m2.18457\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 042 | loss: 2.18457 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m2.18337\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 043 | loss: 2.18337 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m2.18219\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 044 | loss: 2.18219 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m2.18102\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 045 | loss: 2.18102 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m2.17983\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 046 | loss: 2.17983 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m2.17861\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 047 | loss: 2.17861 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m2.17735\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 048 | loss: 2.17735 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m2.17604\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 049 | loss: 2.17604 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m2.17688\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 050 | loss: 2.17688 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m2.17513\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 051 | loss: 2.17513 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m2.17339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 052 | loss: 2.17339 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m2.17163\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 053 | loss: 2.17163 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m2.16983\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 054 | loss: 2.16983 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m2.16799\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 055 | loss: 2.16799 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m2.16609\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 056 | loss: 2.16609 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m2.16411\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 057 | loss: 2.16411 - acc: 0.1613 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m2.16206\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 058 | loss: 2.16206 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m2.15992\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 059 | loss: 2.15992 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m2.15768\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 060 | loss: 2.15768 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m2.15535\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 061 | loss: 2.15535 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m2.15291\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 062 | loss: 2.15291 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m2.15037\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 063 | loss: 2.15037 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m2.15301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 064 | loss: 2.15301 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m2.14963\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 065 | loss: 2.14963 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m2.14625\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 066 | loss: 2.14625 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m2.14285\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 067 | loss: 2.14285 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m2.14910\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 068 | loss: 2.14910 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m2.14455\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 069 | loss: 2.14455 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m2.15126\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 070 | loss: 2.15126 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m2.14578\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 071 | loss: 2.14578 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m2.14058\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 072 | loss: 2.14058 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m2.13560\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 073 | loss: 2.13560 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m2.13079\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 074 | loss: 2.13079 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m2.12608\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 075 | loss: 2.12608 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m2.12145\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 076 | loss: 2.12145 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m2.11685\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 077 | loss: 2.11685 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m2.11226\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 078 | loss: 2.11226 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m2.10766\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 079 | loss: 2.10766 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m2.10303\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 080 | loss: 2.10303 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m2.09834\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 081 | loss: 2.09834 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m2.09359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 082 | loss: 2.09359 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m2.08871\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 083 | loss: 2.08871 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m2.08369\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 084 | loss: 2.08369 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m2.07853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 085 | loss: 2.07853 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m2.07323\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 086 | loss: 2.07323 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m2.06778\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 087 | loss: 2.06778 - acc: 0.1613 -- iter: 31/31\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m2.07497\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 088 | loss: 2.07497 - acc: 0.1581 -- iter: 31/31\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m2.06801\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 089 | loss: 2.06801 - acc: 0.1584 -- iter: 31/31\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m2.06109\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 090 | loss: 2.06109 - acc: 0.1587 -- iter: 31/31\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m2.05419\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 091 | loss: 2.05419 - acc: 0.1589 -- iter: 31/31\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m2.04728\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 092 | loss: 2.04728 - acc: 0.1624 -- iter: 31/31\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m2.04034\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 093 | loss: 2.04034 - acc: 0.1655 -- iter: 31/31\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m2.03337\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 094 | loss: 2.03337 - acc: 0.1683 -- iter: 31/31\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m2.02636\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 095 | loss: 2.02636 - acc: 0.1741 -- iter: 31/31\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m2.01929\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 096 | loss: 2.01929 - acc: 0.1792 -- iter: 31/31\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m2.01216\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 097 | loss: 2.01216 - acc: 0.1871 -- iter: 31/31\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m2.03954\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 098 | loss: 2.03954 - acc: 0.1878 -- iter: 31/31\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m2.02900\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 099 | loss: 2.02900 - acc: 0.2012 -- iter: 31/31\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m2.01888\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 100 | loss: 2.01888 - acc: 0.2134 -- iter: 31/31\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m2.00911\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 101 | loss: 2.00911 - acc: 0.2275 -- iter: 31/31\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m2.02295\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 102 | loss: 2.02295 - acc: 0.2145 -- iter: 31/31\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m2.01151\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 103 | loss: 2.01151 - acc: 0.2253 -- iter: 31/31\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m2.03587\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 104 | loss: 2.03587 - acc: 0.2189 -- iter: 31/31\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m2.02203\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 105 | loss: 2.02203 - acc: 0.2292 -- iter: 31/31\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m2.00905\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 106 | loss: 2.00905 - acc: 0.2386 -- iter: 31/31\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m1.99682\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 107 | loss: 1.99682 - acc: 0.2437 -- iter: 31/31\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m1.98524\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 108 | loss: 1.98524 - acc: 0.2549 -- iter: 31/31\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m1.97421\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 109 | loss: 1.97421 - acc: 0.2713 -- iter: 31/31\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m1.96367\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 110 | loss: 1.96367 - acc: 0.2829 -- iter: 31/31\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m1.95355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 111 | loss: 1.95355 - acc: 0.2933 -- iter: 31/31\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m1.94380\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 112 | loss: 1.94380 - acc: 0.2995 -- iter: 31/31\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m1.93437\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 113 | loss: 1.93437 - acc: 0.3018 -- iter: 31/31\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m1.92522\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 114 | loss: 1.92522 - acc: 0.3039 -- iter: 31/31\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m1.91631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 115 | loss: 1.91631 - acc: 0.3057 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m1.90762\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 116 | loss: 1.90762 - acc: 0.3074 -- iter: 31/31\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m1.89912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 117 | loss: 1.89912 - acc: 0.3089 -- iter: 31/31\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m1.89080\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 118 | loss: 1.89080 - acc: 0.3103 -- iter: 31/31\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m1.88263\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 119 | loss: 1.88263 - acc: 0.3083 -- iter: 31/31\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m1.87461\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 120 | loss: 1.87461 - acc: 0.3065 -- iter: 31/31\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m1.86672\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 121 | loss: 1.86672 - acc: 0.3049 -- iter: 31/31\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m1.85895\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 122 | loss: 1.85895 - acc: 0.3034 -- iter: 31/31\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m1.85129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 123 | loss: 1.85129 - acc: 0.3021 -- iter: 31/31\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m1.84375\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 124 | loss: 1.84375 - acc: 0.3009 -- iter: 31/31\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m1.83631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 125 | loss: 1.83631 - acc: 0.2966 -- iter: 31/31\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m1.87124\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 126 | loss: 1.87124 - acc: 0.2831 -- iter: 31/31\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m1.85990\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 127 | loss: 1.85990 - acc: 0.2806 -- iter: 31/31\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m1.84916\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 128 | loss: 1.84916 - acc: 0.2784 -- iter: 31/31\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m1.83897\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 129 | loss: 1.83897 - acc: 0.2763 -- iter: 31/31\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m1.82927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 130 | loss: 1.82927 - acc: 0.2745 -- iter: 31/31\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m1.82000\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 131 | loss: 1.82000 - acc: 0.2729 -- iter: 31/31\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m1.81114\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 132 | loss: 1.81114 - acc: 0.2714 -- iter: 31/31\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m1.80263\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 133 | loss: 1.80263 - acc: 0.2700 -- iter: 31/31\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m1.87399\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 134 | loss: 1.87399 - acc: 0.2559 -- iter: 31/31\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m1.85833\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 135 | loss: 1.85833 - acc: 0.2562 -- iter: 31/31\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m1.88712\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 136 | loss: 1.88712 - acc: 0.2467 -- iter: 31/31\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m1.86951\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 137 | loss: 1.86951 - acc: 0.2478 -- iter: 31/31\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m1.92265\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 138 | loss: 1.92265 - acc: 0.2359 -- iter: 31/31\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m1.90104\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 139 | loss: 1.90104 - acc: 0.2381 -- iter: 31/31\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m1.88139\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 140 | loss: 1.88139 - acc: 0.2401 -- iter: 31/31\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m1.86349\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 141 | loss: 1.86349 - acc: 0.2419 -- iter: 31/31\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m1.84714\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 142 | loss: 1.84714 - acc: 0.2468 -- iter: 31/31\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m1.83215\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 143 | loss: 1.83215 - acc: 0.2511 -- iter: 31/31\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m1.81837\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 144 | loss: 1.81837 - acc: 0.2550 -- iter: 31/31\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m1.80567\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 145 | loss: 1.80567 - acc: 0.2586 -- iter: 31/31\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m1.79392\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 146 | loss: 1.79392 - acc: 0.2617 -- iter: 31/31\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m1.78301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 147 | loss: 1.78301 - acc: 0.2646 -- iter: 31/31\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m1.77285\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 148 | loss: 1.77285 - acc: 0.2672 -- iter: 31/31\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m1.76335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 149 | loss: 1.76335 - acc: 0.2695 -- iter: 31/31\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m1.83183\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 150 | loss: 1.83183 - acc: 0.2587 -- iter: 31/31\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m1.81584\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 151 | loss: 1.81584 - acc: 0.2618 -- iter: 31/31\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m1.80120\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 152 | loss: 1.80120 - acc: 0.2647 -- iter: 31/31\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m1.78776\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 153 | loss: 1.78776 - acc: 0.2672 -- iter: 31/31\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m1.77539\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 154 | loss: 1.77539 - acc: 0.2696 -- iter: 31/31\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m1.76396\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 155 | loss: 1.76396 - acc: 0.2716 -- iter: 31/31\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m1.75337\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 156 | loss: 1.75337 - acc: 0.2735 -- iter: 31/31\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m1.74353\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 157 | loss: 1.74353 - acc: 0.2720 -- iter: 31/31\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m1.73436\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 158 | loss: 1.73436 - acc: 0.2706 -- iter: 31/31\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m1.72577\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 159 | loss: 1.72577 - acc: 0.2693 -- iter: 31/31\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m1.71772\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 160 | loss: 1.71772 - acc: 0.2682 -- iter: 31/31\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m1.71014\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 161 | loss: 1.71014 - acc: 0.2672 -- iter: 31/31\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m1.70298\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 162 | loss: 1.70298 - acc: 0.2663 -- iter: 31/31\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m1.69619\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 163 | loss: 1.69619 - acc: 0.2654 -- iter: 31/31\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m1.77244\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 164 | loss: 1.77244 - acc: 0.2518 -- iter: 31/31\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m1.75814\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 165 | loss: 1.75814 - acc: 0.2524 -- iter: 31/31\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m1.74505\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 166 | loss: 1.74505 - acc: 0.2530 -- iter: 31/31\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m1.73301\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 167 | loss: 1.73301 - acc: 0.2535 -- iter: 31/31\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m1.72192\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 168 | loss: 1.72192 - acc: 0.2540 -- iter: 31/31\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m1.71168\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 169 | loss: 1.71168 - acc: 0.2544 -- iter: 31/31\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m1.70220\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 170 | loss: 1.70220 - acc: 0.2547 -- iter: 31/31\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m1.69338\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 171 | loss: 1.69338 - acc: 0.2551 -- iter: 31/31\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m1.68516\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 172 | loss: 1.68516 - acc: 0.2554 -- iter: 31/31\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m1.67748\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 173 | loss: 1.67748 - acc: 0.2556 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m1.67027\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 174 | loss: 1.67027 - acc: 0.2559 -- iter: 31/31\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m1.66349\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 175 | loss: 1.66349 - acc: 0.2561 -- iter: 31/31\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m1.80474\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 176 | loss: 1.80474 - acc: 0.2434 -- iter: 31/31\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m1.78411\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 177 | loss: 1.78411 - acc: 0.2449 -- iter: 31/31\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m1.76540\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 178 | loss: 1.76540 - acc: 0.2462 -- iter: 31/31\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m1.74842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 179 | loss: 1.74842 - acc: 0.2474 -- iter: 31/31\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m1.73297\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 180 | loss: 1.73297 - acc: 0.2484 -- iter: 31/31\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m1.71889\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 181 | loss: 1.71889 - acc: 0.2494 -- iter: 31/31\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m1.70604\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 182 | loss: 1.70604 - acc: 0.2503 -- iter: 31/31\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m1.69427\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 183 | loss: 1.69427 - acc: 0.2510 -- iter: 31/31\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m1.68347\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 184 | loss: 1.68347 - acc: 0.2517 -- iter: 31/31\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m1.67353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 185 | loss: 1.67353 - acc: 0.2524 -- iter: 31/31\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m1.66437\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 186 | loss: 1.66437 - acc: 0.2529 -- iter: 31/31\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m1.65590\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 187 | loss: 1.65590 - acc: 0.2535 -- iter: 31/31\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m1.64803\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 188 | loss: 1.64803 - acc: 0.2539 -- iter: 31/31\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m1.64072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 189 | loss: 1.64072 - acc: 0.2543 -- iter: 31/31\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m1.72629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 190 | loss: 1.72629 - acc: 0.2386 -- iter: 31/31\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m1.71075\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 191 | loss: 1.71075 - acc: 0.2405 -- iter: 31/31\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m1.69661\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 192 | loss: 1.69661 - acc: 0.2423 -- iter: 31/31\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m1.68370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 193 | loss: 1.68370 - acc: 0.2439 -- iter: 31/31\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m1.67190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 194 | loss: 1.67190 - acc: 0.2453 -- iter: 31/31\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m1.66109\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 195 | loss: 1.66109 - acc: 0.2466 -- iter: 31/31\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m1.65116\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 196 | loss: 1.65116 - acc: 0.2477 -- iter: 31/31\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m1.64201\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 197 | loss: 1.64201 - acc: 0.2487 -- iter: 31/31\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m1.63357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 198 | loss: 1.63357 - acc: 0.2497 -- iter: 31/31\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m1.62575\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 199 | loss: 1.62575 - acc: 0.2505 -- iter: 31/31\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m1.61849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 200 | loss: 1.61849 - acc: 0.2513 -- iter: 31/31\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m1.61173\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 201 | loss: 1.61173 - acc: 0.2519 -- iter: 31/31\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m1.60542\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 202 | loss: 1.60542 - acc: 0.2526 -- iter: 31/31\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m1.59950\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 203 | loss: 1.59950 - acc: 0.2531 -- iter: 31/31\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m1.68379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 204 | loss: 1.68379 - acc: 0.2472 -- iter: 31/31\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m1.66965\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 205 | loss: 1.66965 - acc: 0.2482 -- iter: 31/31\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m1.65676\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 206 | loss: 1.65676 - acc: 0.2525 -- iter: 31/31\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m1.64499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 207 | loss: 1.64499 - acc: 0.2562 -- iter: 31/31\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m1.63421\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 208 | loss: 1.63421 - acc: 0.2596 -- iter: 31/31\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m1.62432\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 209 | loss: 1.62432 - acc: 0.2627 -- iter: 31/31\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m1.73657\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 210 | loss: 1.73657 - acc: 0.2493 -- iter: 31/31\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m1.71617\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 211 | loss: 1.71617 - acc: 0.2534 -- iter: 31/31\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m1.84350\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 212 | loss: 1.84350 - acc: 0.2442 -- iter: 31/31\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m1.81232\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 213 | loss: 1.81232 - acc: 0.2521 -- iter: 31/31\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m1.78424\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 214 | loss: 1.78424 - acc: 0.2591 -- iter: 31/31\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m1.75894\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 215 | loss: 1.75894 - acc: 0.2655 -- iter: 31/31\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m1.73612\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 216 | loss: 1.73612 - acc: 0.2712 -- iter: 31/31\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m1.71551\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 217 | loss: 1.71551 - acc: 0.2763 -- iter: 31/31\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m1.87790\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 218 | loss: 1.87790 - acc: 0.2584 -- iter: 31/31\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m1.84308\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 219 | loss: 1.84308 - acc: 0.2680 -- iter: 31/31\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m1.81177\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 220 | loss: 1.81177 - acc: 0.2767 -- iter: 31/31\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m1.78359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 221 | loss: 1.78359 - acc: 0.2845 -- iter: 31/31\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m1.75820\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 222 | loss: 1.75820 - acc: 0.2915 -- iter: 31/31\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m1.73531\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 223 | loss: 1.73531 - acc: 0.2979 -- iter: 31/31\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m1.88194\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 224 | loss: 1.88194 - acc: 0.2842 -- iter: 31/31\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m1.84667\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 225 | loss: 1.84667 - acc: 0.2913 -- iter: 31/31\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m1.81496\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 226 | loss: 1.81496 - acc: 0.2976 -- iter: 31/31\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m1.78643\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 227 | loss: 1.78643 - acc: 0.3034 -- iter: 31/31\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m1.76074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 228 | loss: 1.76074 - acc: 0.3085 -- iter: 31/31\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m1.73757\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 229 | loss: 1.73757 - acc: 0.3131 -- iter: 31/31\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m1.85087\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 230 | loss: 1.85087 - acc: 0.2947 -- iter: 31/31\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m1.81868\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 231 | loss: 1.81868 - acc: 0.3007 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m1.78973\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 232 | loss: 1.78973 - acc: 0.3061 -- iter: 31/31\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m1.76366\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 233 | loss: 1.76366 - acc: 0.3110 -- iter: 31/31\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m1.74017\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 234 | loss: 1.74017 - acc: 0.3154 -- iter: 31/31\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m1.71898\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 235 | loss: 1.71898 - acc: 0.3193 -- iter: 31/31\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m1.82619\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 236 | loss: 1.82619 - acc: 0.3035 -- iter: 31/31\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m1.79634\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 237 | loss: 1.79634 - acc: 0.3087 -- iter: 31/31\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m1.76947\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 238 | loss: 1.76947 - acc: 0.3133 -- iter: 31/31\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m1.74526\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 239 | loss: 1.74526 - acc: 0.3174 -- iter: 31/31\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m1.87043\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 240 | loss: 1.87043 - acc: 0.2986 -- iter: 31/31\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m1.83614\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 241 | loss: 1.83614 - acc: 0.3042 -- iter: 31/31\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m1.80530\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 242 | loss: 1.80530 - acc: 0.3093 -- iter: 31/31\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m1.77756\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 243 | loss: 1.77756 - acc: 0.3138 -- iter: 31/31\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m1.75257\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 244 | loss: 1.75257 - acc: 0.3179 -- iter: 31/31\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m1.73003\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 245 | loss: 1.73003 - acc: 0.3216 -- iter: 31/31\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m1.70969\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 246 | loss: 1.70969 - acc: 0.3250 -- iter: 31/31\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m1.69129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 247 | loss: 1.69129 - acc: 0.3279 -- iter: 31/31\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m1.67463\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 248 | loss: 1.67463 - acc: 0.3306 -- iter: 31/31\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m1.65953\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 249 | loss: 1.65953 - acc: 0.3331 -- iter: 31/31\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m1.64580\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 250 | loss: 1.64580 - acc: 0.3352 -- iter: 31/31\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m1.63330\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 251 | loss: 1.63330 - acc: 0.3372 -- iter: 31/31\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m1.62189\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 252 | loss: 1.62189 - acc: 0.3390 -- iter: 31/31\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m1.61146\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 253 | loss: 1.61146 - acc: 0.3405 -- iter: 31/31\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m1.60189\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 254 | loss: 1.60189 - acc: 0.3420 -- iter: 31/31\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m1.59310\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 255 | loss: 1.59310 - acc: 0.3433 -- iter: 31/31\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m1.58500\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 256 | loss: 1.58500 - acc: 0.3444 -- iter: 31/31\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m1.57752\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 257 | loss: 1.57752 - acc: 0.3455 -- iter: 31/31\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m1.57058\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 258 | loss: 1.57058 - acc: 0.3464 -- iter: 31/31\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m1.56413\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 259 | loss: 1.56413 - acc: 0.3472 -- iter: 31/31\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m1.55812\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 260 | loss: 1.55812 - acc: 0.3480 -- iter: 31/31\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m1.55249\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 261 | loss: 1.55249 - acc: 0.3487 -- iter: 31/31\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m1.54721\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 262 | loss: 1.54721 - acc: 0.3493 -- iter: 31/31\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m1.54224\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 263 | loss: 1.54224 - acc: 0.3499 -- iter: 31/31\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m1.53755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 264 | loss: 1.53755 - acc: 0.3504 -- iter: 31/31\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m1.53311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 265 | loss: 1.53311 - acc: 0.3508 -- iter: 31/31\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m1.52889\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 266 | loss: 1.52889 - acc: 0.3512 -- iter: 31/31\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m1.52487\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 267 | loss: 1.52487 - acc: 0.3516 -- iter: 31/31\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m1.52103\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 268 | loss: 1.52103 - acc: 0.3519 -- iter: 31/31\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m1.51735\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 269 | loss: 1.51735 - acc: 0.3522 -- iter: 31/31\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m1.66073\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 270 | loss: 1.66073 - acc: 0.3266 -- iter: 31/31\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m1.64275\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 271 | loss: 1.64275 - acc: 0.3295 -- iter: 31/31\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m1.75425\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 272 | loss: 1.75425 - acc: 0.3062 -- iter: 31/31\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m1.72676\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 273 | loss: 1.72676 - acc: 0.3143 -- iter: 31/31\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m1.70196\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 274 | loss: 1.70196 - acc: 0.3216 -- iter: 31/31\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m1.67957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 275 | loss: 1.67957 - acc: 0.3281 -- iter: 31/31\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m1.65933\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 276 | loss: 1.65933 - acc: 0.3340 -- iter: 31/31\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m1.64102\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 277 | loss: 1.64102 - acc: 0.3393 -- iter: 31/31\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m1.62442\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 278 | loss: 1.62442 - acc: 0.3441 -- iter: 31/31\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m1.60935\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 279 | loss: 1.60935 - acc: 0.3484 -- iter: 31/31\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m1.59566\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 280 | loss: 1.59566 - acc: 0.3523 -- iter: 31/31\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m1.58319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 281 | loss: 1.58319 - acc: 0.3558 -- iter: 31/31\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m1.57181\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 282 | loss: 1.57181 - acc: 0.3589 -- iter: 31/31\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m1.56141\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 283 | loss: 1.56141 - acc: 0.3617 -- iter: 31/31\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m1.55188\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 284 | loss: 1.55188 - acc: 0.3642 -- iter: 31/31\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m1.54313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 285 | loss: 1.54313 - acc: 0.3665 -- iter: 31/31\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m1.53508\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 286 | loss: 1.53508 - acc: 0.3686 -- iter: 31/31\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m1.52764\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 287 | loss: 1.52764 - acc: 0.3704 -- iter: 31/31\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m1.52076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 288 | loss: 1.52076 - acc: 0.3721 -- iter: 31/31\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m1.51437\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 289 | loss: 1.51437 - acc: 0.3768 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m1.50842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 290 | loss: 1.50842 - acc: 0.3811 -- iter: 31/31\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m1.50287\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 291 | loss: 1.50287 - acc: 0.3849 -- iter: 31/31\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m1.64397\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 292 | loss: 1.64397 - acc: 0.3593 -- iter: 31/31\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m1.62455\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 293 | loss: 1.62455 - acc: 0.3653 -- iter: 31/31\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m1.60697\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 294 | loss: 1.60697 - acc: 0.3707 -- iter: 31/31\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m1.59101\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 295 | loss: 1.59101 - acc: 0.3756 -- iter: 31/31\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m1.57652\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 296 | loss: 1.57652 - acc: 0.3800 -- iter: 31/31\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m1.56333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 297 | loss: 1.56333 - acc: 0.3839 -- iter: 31/31\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m1.55130\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 298 | loss: 1.55130 - acc: 0.3875 -- iter: 31/31\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m1.54032\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 299 | loss: 1.54032 - acc: 0.3906 -- iter: 31/31\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m1.53027\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 300 | loss: 1.53027 - acc: 0.3935 -- iter: 31/31\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m1.52105\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 301 | loss: 1.52105 - acc: 0.3961 -- iter: 31/31\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m1.51257\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 302 | loss: 1.51257 - acc: 0.3984 -- iter: 31/31\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m1.50476\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 303 | loss: 1.50476 - acc: 0.4005 -- iter: 31/31\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m1.72367\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 304 | loss: 1.72367 - acc: 0.3637 -- iter: 31/31\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m1.69453\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 305 | loss: 1.69453 - acc: 0.3693 -- iter: 31/31\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m1.66824\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 306 | loss: 1.66824 - acc: 0.3743 -- iter: 31/31\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m1.64452\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 307 | loss: 1.64452 - acc: 0.3788 -- iter: 31/31\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m1.62309\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 308 | loss: 1.62309 - acc: 0.3828 -- iter: 31/31\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m1.60370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 309 | loss: 1.60370 - acc: 0.3865 -- iter: 31/31\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m1.58614\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 310 | loss: 1.58614 - acc: 0.3930 -- iter: 31/31\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m1.57021\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 311 | loss: 1.57021 - acc: 0.3989 -- iter: 31/31\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m1.55575\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 312 | loss: 1.55575 - acc: 0.4041 -- iter: 31/31\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m1.54258\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 313 | loss: 1.54258 - acc: 0.4089 -- iter: 31/31\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m1.53058\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 314 | loss: 1.53058 - acc: 0.4132 -- iter: 31/31\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m1.51962\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 315 | loss: 1.51962 - acc: 0.4170 -- iter: 31/31\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m1.50959\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 316 | loss: 1.50959 - acc: 0.4205 -- iter: 31/31\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m1.50039\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 317 | loss: 1.50039 - acc: 0.4236 -- iter: 31/31\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m1.49193\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 318 | loss: 1.49193 - acc: 0.4264 -- iter: 31/31\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m1.48413\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 319 | loss: 1.48413 - acc: 0.4289 -- iter: 31/31\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m1.47692\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 320 | loss: 1.47692 - acc: 0.4312 -- iter: 31/31\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m1.47023\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 321 | loss: 1.47023 - acc: 0.4332 -- iter: 31/31\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m1.46402\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 322 | loss: 1.46402 - acc: 0.4351 -- iter: 31/31\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m1.45822\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 323 | loss: 1.45822 - acc: 0.4367 -- iter: 31/31\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m1.45280\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 324 | loss: 1.45280 - acc: 0.4382 -- iter: 31/31\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m1.44772\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 325 | loss: 1.44772 - acc: 0.4395 -- iter: 31/31\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m1.63507\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 326 | loss: 1.63507 - acc: 0.4085 -- iter: 31/31\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m1.61146\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 327 | loss: 1.61146 - acc: 0.4160 -- iter: 31/31\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m1.59012\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 328 | loss: 1.59012 - acc: 0.4228 -- iter: 31/31\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m1.57081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 329 | loss: 1.57081 - acc: 0.4289 -- iter: 31/31\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m1.79123\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 330 | loss: 1.79123 - acc: 0.4054 -- iter: 31/31\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m1.75170\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 331 | loss: 1.75170 - acc: 0.4132 -- iter: 31/31\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m1.71611\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 332 | loss: 1.71611 - acc: 0.4203 -- iter: 31/31\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m1.68406\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 333 | loss: 1.68406 - acc: 0.4267 -- iter: 31/31\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m1.65517\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 334 | loss: 1.65517 - acc: 0.4324 -- iter: 31/31\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m1.62910\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 335 | loss: 1.62910 - acc: 0.4375 -- iter: 31/31\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m1.60556\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 336 | loss: 1.60556 - acc: 0.4422 -- iter: 31/31\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m1.58427\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 337 | loss: 1.58427 - acc: 0.4463 -- iter: 31/31\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m1.56500\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 338 | loss: 1.56500 - acc: 0.4501 -- iter: 31/31\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m1.54754\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 339 | loss: 1.54754 - acc: 0.4535 -- iter: 31/31\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m1.53168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 340 | loss: 1.53168 - acc: 0.4597 -- iter: 31/31\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m1.51726\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 341 | loss: 1.51726 - acc: 0.4654 -- iter: 31/31\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m1.50413\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 342 | loss: 1.50413 - acc: 0.4704 -- iter: 31/31\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m1.49215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 343 | loss: 1.49215 - acc: 0.4750 -- iter: 31/31\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m1.48119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 344 | loss: 1.48119 - acc: 0.4791 -- iter: 31/31\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m1.47114\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 345 | loss: 1.47114 - acc: 0.4828 -- iter: 31/31\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m1.46191\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 346 | loss: 1.46191 - acc: 0.4862 -- iter: 31/31\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m1.45341\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 347 | loss: 1.45341 - acc: 0.4892 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m1.44556\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 348 | loss: 1.44556 - acc: 0.4919 -- iter: 31/31\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m1.43829\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 349 | loss: 1.43829 - acc: 0.4943 -- iter: 31/31\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m1.64780\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 350 | loss: 1.64780 - acc: 0.4481 -- iter: 31/31\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m1.62002\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 351 | loss: 1.62002 - acc: 0.4549 -- iter: 31/31\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m1.59493\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 352 | loss: 1.59493 - acc: 0.4610 -- iter: 31/31\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m1.57224\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 353 | loss: 1.57224 - acc: 0.4665 -- iter: 31/31\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m1.75064\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 354 | loss: 1.75064 - acc: 0.4263 -- iter: 31/31\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m1.71226\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 355 | loss: 1.71226 - acc: 0.4353 -- iter: 31/31\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m1.87345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 356 | loss: 1.87345 - acc: 0.4047 -- iter: 31/31\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m1.82283\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 357 | loss: 1.82283 - acc: 0.4158 -- iter: 31/31\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m1.77732\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 358 | loss: 1.77732 - acc: 0.4291 -- iter: 31/31\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m1.73638\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 359 | loss: 1.73638 - acc: 0.4410 -- iter: 31/31\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m1.69952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 360 | loss: 1.69952 - acc: 0.4517 -- iter: 31/31\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m1.66632\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 361 | loss: 1.66632 - acc: 0.4614 -- iter: 31/31\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m1.63638\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 362 | loss: 1.63638 - acc: 0.4701 -- iter: 31/31\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m1.60936\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 363 | loss: 1.60936 - acc: 0.4812 -- iter: 31/31\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m1.58495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 364 | loss: 1.58495 - acc: 0.4911 -- iter: 31/31\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m1.56286\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 365 | loss: 1.56286 - acc: 0.5001 -- iter: 31/31\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m1.70891\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 366 | loss: 1.70891 - acc: 0.4597 -- iter: 31/31\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m1.67429\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 367 | loss: 1.67429 - acc: 0.4783 -- iter: 31/31\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m1.82574\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 368 | loss: 1.82574 - acc: 0.4595 -- iter: 31/31\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m1.77947\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 369 | loss: 1.77947 - acc: 0.4780 -- iter: 31/31\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m1.73785\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 370 | loss: 1.73785 - acc: 0.4948 -- iter: 31/31\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m1.70041\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 371 | loss: 1.70041 - acc: 0.5098 -- iter: 31/31\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m1.66668\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 372 | loss: 1.66668 - acc: 0.5233 -- iter: 31/31\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m1.63628\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 373 | loss: 1.63628 - acc: 0.5355 -- iter: 31/31\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m1.60885\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 374 | loss: 1.60885 - acc: 0.5465 -- iter: 31/31\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m1.58406\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 375 | loss: 1.58406 - acc: 0.5564 -- iter: 31/31\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m1.56164\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 376 | loss: 1.56164 - acc: 0.5652 -- iter: 31/31\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m1.54133\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 377 | loss: 1.54133 - acc: 0.5732 -- iter: 31/31\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m1.52289\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 378 | loss: 1.52289 - acc: 0.5804 -- iter: 31/31\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m1.50614\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 379 | loss: 1.50614 - acc: 0.5869 -- iter: 31/31\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m1.49088\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 380 | loss: 1.49088 - acc: 0.5927 -- iter: 31/31\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m1.47696\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 381 | loss: 1.47696 - acc: 0.5980 -- iter: 31/31\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m1.46423\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 382 | loss: 1.46423 - acc: 0.6027 -- iter: 31/31\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m1.45256\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 383 | loss: 1.45256 - acc: 0.6069 -- iter: 31/31\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m1.44184\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 384 | loss: 1.44184 - acc: 0.6108 -- iter: 31/31\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m1.43196\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 385 | loss: 1.43196 - acc: 0.6142 -- iter: 31/31\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m1.42283\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 386 | loss: 1.42283 - acc: 0.6173 -- iter: 31/31\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m1.41438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 387 | loss: 1.41438 - acc: 0.6201 -- iter: 31/31\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m1.40653\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 388 | loss: 1.40653 - acc: 0.6226 -- iter: 31/31\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m1.39921\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 389 | loss: 1.39921 - acc: 0.6248 -- iter: 31/31\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m1.39236\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 390 | loss: 1.39236 - acc: 0.6269 -- iter: 31/31\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m1.38594\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 391 | loss: 1.38594 - acc: 0.6287 -- iter: 31/31\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m1.54021\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 392 | loss: 1.54021 - acc: 0.5820 -- iter: 31/31\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m1.51859\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 393 | loss: 1.51859 - acc: 0.5883 -- iter: 31/31\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m1.49897\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 394 | loss: 1.49897 - acc: 0.5940 -- iter: 31/31\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m1.48113\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 395 | loss: 1.48113 - acc: 0.5991 -- iter: 31/31\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m1.66844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 396 | loss: 1.66844 - acc: 0.5585 -- iter: 31/31\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m1.63339\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 397 | loss: 1.63339 - acc: 0.5672 -- iter: 31/31\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m1.76763\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 398 | loss: 1.76763 - acc: 0.5234 -- iter: 31/31\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m1.72258\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 399 | loss: 1.72258 - acc: 0.5388 -- iter: 31/31\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m1.68200\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 400 | loss: 1.68200 - acc: 0.5526 -- iter: 31/31\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m1.64543\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 401 | loss: 1.64543 - acc: 0.5651 -- iter: 31/31\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m1.61245\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 402 | loss: 1.61245 - acc: 0.5764 -- iter: 31/31\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m1.58266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 403 | loss: 1.58266 - acc: 0.5865 -- iter: 31/31\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m1.55574\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 404 | loss: 1.55574 - acc: 0.5956 -- iter: 31/31\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m1.53137\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 405 | loss: 1.53137 - acc: 0.6037 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m1.71099\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 406 | loss: 1.71099 - acc: 0.5530 -- iter: 31/31\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m1.67092\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 407 | loss: 1.67092 - acc: 0.5655 -- iter: 31/31\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m1.63480\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 408 | loss: 1.63480 - acc: 0.5767 -- iter: 31/31\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m1.60221\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 409 | loss: 1.60221 - acc: 0.5868 -- iter: 31/31\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m1.57278\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 410 | loss: 1.57278 - acc: 0.5958 -- iter: 31/31\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m1.54617\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 411 | loss: 1.54617 - acc: 0.6040 -- iter: 31/31\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m1.52208\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 412 | loss: 1.52208 - acc: 0.6113 -- iter: 31/31\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m1.50024\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 413 | loss: 1.50024 - acc: 0.6179 -- iter: 31/31\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m1.68206\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 414 | loss: 1.68206 - acc: 0.5723 -- iter: 31/31\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m1.64400\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 415 | loss: 1.64400 - acc: 0.5828 -- iter: 31/31\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m1.60967\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 416 | loss: 1.60967 - acc: 0.5922 -- iter: 31/31\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m1.57867\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 417 | loss: 1.57867 - acc: 0.5975 -- iter: 31/31\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m1.55065\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 418 | loss: 1.55065 - acc: 0.6023 -- iter: 31/31\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m1.52529\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 419 | loss: 1.52529 - acc: 0.6066 -- iter: 31/31\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m1.50231\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 420 | loss: 1.50231 - acc: 0.6104 -- iter: 31/31\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m1.48145\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 421 | loss: 1.48145 - acc: 0.6139 -- iter: 31/31\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m1.46248\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 422 | loss: 1.46248 - acc: 0.6170 -- iter: 31/31\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m1.44520\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 423 | loss: 1.44520 - acc: 0.6199 -- iter: 31/31\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m1.42943\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 424 | loss: 1.42943 - acc: 0.6224 -- iter: 31/31\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m1.41500\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 425 | loss: 1.41500 - acc: 0.6247 -- iter: 31/31\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m1.40178\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 426 | loss: 1.40178 - acc: 0.6267 -- iter: 31/31\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m1.38962\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 427 | loss: 1.38962 - acc: 0.6286 -- iter: 31/31\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m1.37842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 428 | loss: 1.37842 - acc: 0.6302 -- iter: 31/31\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m1.36807\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 429 | loss: 1.36807 - acc: 0.6317 -- iter: 31/31\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m1.35848\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 430 | loss: 1.35848 - acc: 0.6331 -- iter: 31/31\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m1.34957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 431 | loss: 1.34957 - acc: 0.6375 -- iter: 31/31\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m1.34126\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 432 | loss: 1.34126 - acc: 0.6415 -- iter: 31/31\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m1.33350\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 433 | loss: 1.33350 - acc: 0.6451 -- iter: 31/31\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m1.55911\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 434 | loss: 1.55911 - acc: 0.5935 -- iter: 31/31\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m1.52912\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 435 | loss: 1.52912 - acc: 0.6019 -- iter: 31/31\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m1.50198\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 436 | loss: 1.50198 - acc: 0.6126 -- iter: 31/31\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m1.47738\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 437 | loss: 1.47738 - acc: 0.6224 -- iter: 31/31\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m1.45504\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 438 | loss: 1.45504 - acc: 0.6311 -- iter: 31/31\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m1.43474\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 439 | loss: 1.43474 - acc: 0.6389 -- iter: 31/31\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m1.41624\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 440 | loss: 1.41624 - acc: 0.6460 -- iter: 31/31\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m1.39937\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 441 | loss: 1.39937 - acc: 0.6524 -- iter: 31/31\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m1.38394\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 442 | loss: 1.38394 - acc: 0.6581 -- iter: 31/31\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m1.36980\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 443 | loss: 1.36980 - acc: 0.6633 -- iter: 31/31\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m1.35681\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 444 | loss: 1.35681 - acc: 0.6679 -- iter: 31/31\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m1.34485\u001b[0m\u001b[0m | time: 0.009s\n",
      "| Adam | epoch: 445 | loss: 1.34485 - acc: 0.6721 -- iter: 31/31\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m1.33381\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 446 | loss: 1.33381 - acc: 0.6758 -- iter: 31/31\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m1.32360\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 447 | loss: 1.32360 - acc: 0.6792 -- iter: 31/31\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m1.31411\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 448 | loss: 1.31411 - acc: 0.6823 -- iter: 31/31\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m1.30528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 449 | loss: 1.30528 - acc: 0.6850 -- iter: 31/31\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m1.29703\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 450 | loss: 1.29703 - acc: 0.6875 -- iter: 31/31\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m1.28930\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 451 | loss: 1.28930 - acc: 0.6897 -- iter: 31/31\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m1.28203\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 452 | loss: 1.28203 - acc: 0.6917 -- iter: 31/31\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m1.27518\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 453 | loss: 1.27518 - acc: 0.6935 -- iter: 31/31\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m1.26870\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 454 | loss: 1.26870 - acc: 0.6951 -- iter: 31/31\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m1.26254\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 455 | loss: 1.26254 - acc: 0.6966 -- iter: 31/31\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m1.43383\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 456 | loss: 1.43383 - acc: 0.6398 -- iter: 31/31\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m1.41062\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 457 | loss: 1.41062 - acc: 0.6468 -- iter: 31/31\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m1.65673\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 458 | loss: 1.65673 - acc: 0.5853 -- iter: 31/31\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m1.61094\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 459 | loss: 1.61094 - acc: 0.5946 -- iter: 31/31\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m1.56963\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 460 | loss: 1.56963 - acc: 0.6028 -- iter: 31/31\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m1.53234\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 461 | loss: 1.53234 - acc: 0.6103 -- iter: 31/31\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m1.49864\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 462 | loss: 1.49864 - acc: 0.6170 -- iter: 31/31\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m1.46814\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 463 | loss: 1.46814 - acc: 0.6231 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m1.44052\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 464 | loss: 1.44052 - acc: 0.6285 -- iter: 31/31\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m1.41547\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 465 | loss: 1.41547 - acc: 0.6334 -- iter: 31/31\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m1.39271\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 466 | loss: 1.39271 - acc: 0.6378 -- iter: 31/31\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m1.37200\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 467 | loss: 1.37200 - acc: 0.6417 -- iter: 31/31\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m1.59775\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 468 | loss: 1.59775 - acc: 0.5873 -- iter: 31/31\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m1.55620\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 469 | loss: 1.55620 - acc: 0.5995 -- iter: 31/31\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m1.51869\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 470 | loss: 1.51869 - acc: 0.6105 -- iter: 31/31\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m1.48479\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 471 | loss: 1.48479 - acc: 0.6204 -- iter: 31/31\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m1.61587\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 472 | loss: 1.61587 - acc: 0.5745 -- iter: 31/31\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m1.57201\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 473 | loss: 1.57201 - acc: 0.5880 -- iter: 31/31\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m1.53243\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 474 | loss: 1.53243 - acc: 0.6002 -- iter: 31/31\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m1.49668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 475 | loss: 1.49668 - acc: 0.6111 -- iter: 31/31\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m1.46434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 476 | loss: 1.46434 - acc: 0.6210 -- iter: 31/31\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m1.43506\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 477 | loss: 1.43506 - acc: 0.6299 -- iter: 31/31\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m1.40850\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 478 | loss: 1.40850 - acc: 0.6378 -- iter: 31/31\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m1.38438\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 479 | loss: 1.38438 - acc: 0.6450 -- iter: 31/31\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m1.36244\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 480 | loss: 1.36244 - acc: 0.6515 -- iter: 31/31\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m1.34245\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 481 | loss: 1.34245 - acc: 0.6573 -- iter: 31/31\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m1.32419\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 482 | loss: 1.32419 - acc: 0.6658 -- iter: 31/31\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m1.30749\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 483 | loss: 1.30749 - acc: 0.6734 -- iter: 31/31\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m1.29217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 484 | loss: 1.29217 - acc: 0.6802 -- iter: 31/31\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m1.27809\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 485 | loss: 1.27809 - acc: 0.6864 -- iter: 31/31\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m1.52427\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 486 | loss: 1.52427 - acc: 0.6307 -- iter: 31/31\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m1.48653\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 487 | loss: 1.48653 - acc: 0.6418 -- iter: 31/31\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m1.45239\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 488 | loss: 1.45239 - acc: 0.6518 -- iter: 31/31\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m1.42148\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 489 | loss: 1.42148 - acc: 0.6608 -- iter: 31/31\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m1.75333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 490 | loss: 1.75333 - acc: 0.6044 -- iter: 31/31\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m1.69211\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 491 | loss: 1.69211 - acc: 0.6182 -- iter: 31/31\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m1.89360\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 492 | loss: 1.89360 - acc: 0.5596 -- iter: 31/31\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m1.81839\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 493 | loss: 1.81839 - acc: 0.5778 -- iter: 31/31\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m1.75074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 494 | loss: 1.75074 - acc: 0.5942 -- iter: 31/31\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m1.68985\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 495 | loss: 1.68985 - acc: 0.6090 -- iter: 31/31\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m1.63502\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 496 | loss: 1.63502 - acc: 0.6223 -- iter: 31/31\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m1.58560\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 497 | loss: 1.58560 - acc: 0.6343 -- iter: 31/31\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m1.54101\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 498 | loss: 1.54101 - acc: 0.6450 -- iter: 31/31\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m1.50076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 499 | loss: 1.50076 - acc: 0.6547 -- iter: 31/31\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m1.46436\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 500 | loss: 1.46436 - acc: 0.6634 -- iter: 31/31\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m1.43142\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 501 | loss: 1.43142 - acc: 0.6713 -- iter: 31/31\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m1.40157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 502 | loss: 1.40157 - acc: 0.6784 -- iter: 31/31\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m1.37447\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 503 | loss: 1.37447 - acc: 0.6847 -- iter: 31/31\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m1.49254\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 504 | loss: 1.49254 - acc: 0.6291 -- iter: 31/31\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m1.45594\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 505 | loss: 1.45594 - acc: 0.6404 -- iter: 31/31\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m1.42282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 506 | loss: 1.42282 - acc: 0.6506 -- iter: 31/31\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m1.39280\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 507 | loss: 1.39280 - acc: 0.6597 -- iter: 31/31\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m1.36555\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 508 | loss: 1.36555 - acc: 0.6679 -- iter: 31/31\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m1.34078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 509 | loss: 1.34078 - acc: 0.6753 -- iter: 31/31\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m1.31823\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 510 | loss: 1.31823 - acc: 0.6820 -- iter: 31/31\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m1.29765\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 511 | loss: 1.29765 - acc: 0.6912 -- iter: 31/31\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m1.51583\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 512 | loss: 1.51583 - acc: 0.6285 -- iter: 31/31\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m1.47507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 513 | loss: 1.47507 - acc: 0.6463 -- iter: 31/31\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m1.43823\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 514 | loss: 1.43823 - acc: 0.6623 -- iter: 31/31\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m1.40488\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 515 | loss: 1.40488 - acc: 0.6768 -- iter: 31/31\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m1.64354\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 516 | loss: 1.64354 - acc: 0.6155 -- iter: 31/31\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m1.58940\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 517 | loss: 1.58940 - acc: 0.6346 -- iter: 31/31\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m1.82413\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 518 | loss: 1.82413 - acc: 0.5712 -- iter: 31/31\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m1.75192\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 519 | loss: 1.75192 - acc: 0.5947 -- iter: 31/31\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m1.68695\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 520 | loss: 1.68695 - acc: 0.6159 -- iter: 31/31\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m1.62847\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 521 | loss: 1.62847 - acc: 0.6349 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m1.86328\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 522 | loss: 1.86328 - acc: 0.5908 -- iter: 31/31\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m1.78718\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 523 | loss: 1.78718 - acc: 0.6124 -- iter: 31/31\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m1.97388\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 524 | loss: 1.97388 - acc: 0.5576 -- iter: 31/31\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m1.88691\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 525 | loss: 1.88691 - acc: 0.5825 -- iter: 31/31\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m1.80873\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 526 | loss: 1.80873 - acc: 0.6049 -- iter: 31/31\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m1.73842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 527 | loss: 1.73842 - acc: 0.6250 -- iter: 31/31\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m1.67514\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 528 | loss: 1.67514 - acc: 0.6432 -- iter: 31/31\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m1.61816\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 529 | loss: 1.61816 - acc: 0.6595 -- iter: 31/31\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m1.75468\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 530 | loss: 1.75468 - acc: 0.6097 -- iter: 31/31\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m1.68970\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 531 | loss: 1.68970 - acc: 0.6293 -- iter: 31/31\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m1.63120\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 532 | loss: 1.63120 - acc: 0.6471 -- iter: 31/31\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m1.57850\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 533 | loss: 1.57850 - acc: 0.6630 -- iter: 31/31\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m1.74792\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 534 | loss: 1.74792 - acc: 0.6128 -- iter: 31/31\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m1.68349\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 535 | loss: 1.68349 - acc: 0.6322 -- iter: 31/31\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m1.62548\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 536 | loss: 1.62548 - acc: 0.6496 -- iter: 31/31\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m1.57321\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 537 | loss: 1.57321 - acc: 0.6685 -- iter: 31/31\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m1.52607\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 538 | loss: 1.52607 - acc: 0.6855 -- iter: 31/31\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m1.48352\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 539 | loss: 1.48352 - acc: 0.7009 -- iter: 31/31\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m1.44506\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 540 | loss: 1.44506 - acc: 0.7146 -- iter: 31/31\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m1.41025\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 541 | loss: 1.41025 - acc: 0.7271 -- iter: 31/31\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m1.37870\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 542 | loss: 1.37870 - acc: 0.7382 -- iter: 31/31\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m1.35006\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 543 | loss: 1.35006 - acc: 0.7483 -- iter: 31/31\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m1.32403\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 544 | loss: 1.32403 - acc: 0.7573 -- iter: 31/31\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m1.30032\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 545 | loss: 1.30032 - acc: 0.7655 -- iter: 31/31\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m1.27868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 546 | loss: 1.27868 - acc: 0.7728 -- iter: 31/31\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m1.25890\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 547 | loss: 1.25890 - acc: 0.7794 -- iter: 31/31\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m1.49938\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 548 | loss: 1.49938 - acc: 0.7208 -- iter: 31/31\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m1.45704\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 549 | loss: 1.45704 - acc: 0.7326 -- iter: 31/31\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m1.65477\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 550 | loss: 1.65477 - acc: 0.6690 -- iter: 31/31\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m1.59665\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 551 | loss: 1.59665 - acc: 0.6860 -- iter: 31/31\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m1.54426\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 552 | loss: 1.54426 - acc: 0.7012 -- iter: 31/31\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m1.49699\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 553 | loss: 1.49699 - acc: 0.7150 -- iter: 31/31\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m1.72471\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 554 | loss: 1.72471 - acc: 0.6596 -- iter: 31/31\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m1.65927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 555 | loss: 1.65927 - acc: 0.6775 -- iter: 31/31\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m1.60035\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 556 | loss: 1.60035 - acc: 0.6936 -- iter: 31/31\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m1.54727\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 557 | loss: 1.54727 - acc: 0.7114 -- iter: 31/31\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m1.49940\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 558 | loss: 1.49940 - acc: 0.7273 -- iter: 31/31\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m1.45618\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 559 | loss: 1.45618 - acc: 0.7417 -- iter: 31/31\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m1.41713\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 560 | loss: 1.41713 - acc: 0.7546 -- iter: 31/31\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m1.38179\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 561 | loss: 1.38179 - acc: 0.7663 -- iter: 31/31\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m1.34977\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 562 | loss: 1.34977 - acc: 0.7767 -- iter: 31/31\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m1.32072\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 563 | loss: 1.32072 - acc: 0.7862 -- iter: 31/31\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m1.29432\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 564 | loss: 1.29432 - acc: 0.7946 -- iter: 31/31\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m1.27028\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 565 | loss: 1.27028 - acc: 0.8023 -- iter: 31/31\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m1.47241\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 566 | loss: 1.47241 - acc: 0.7317 -- iter: 31/31\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m1.43013\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 567 | loss: 1.43013 - acc: 0.7489 -- iter: 31/31\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m1.39190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 568 | loss: 1.39190 - acc: 0.7643 -- iter: 31/31\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m1.35730\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 569 | loss: 1.35730 - acc: 0.7782 -- iter: 31/31\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m1.32593\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 570 | loss: 1.32593 - acc: 0.7907 -- iter: 31/31\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m1.29746\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 571 | loss: 1.29746 - acc: 0.8020 -- iter: 31/31\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m1.27157\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 572 | loss: 1.27157 - acc: 0.8121 -- iter: 31/31\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m1.24800\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 573 | loss: 1.24800 - acc: 0.8212 -- iter: 31/31\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m1.22650\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 574 | loss: 1.22650 - acc: 0.8294 -- iter: 31/31\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m1.20684\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 575 | loss: 1.20684 - acc: 0.8368 -- iter: 31/31\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m1.18883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 576 | loss: 1.18883 - acc: 0.8434 -- iter: 31/31\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m1.17231\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 577 | loss: 1.17231 - acc: 0.8494 -- iter: 31/31\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m1.15710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 578 | loss: 1.15710 - acc: 0.8548 -- iter: 31/31\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m1.14308\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 579 | loss: 1.14308 - acc: 0.8596 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m1.13012\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 580 | loss: 1.13012 - acc: 0.8640 -- iter: 31/31\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m1.11810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 581 | loss: 1.11810 - acc: 0.8679 -- iter: 31/31\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m1.10693\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 582 | loss: 1.10693 - acc: 0.8714 -- iter: 31/31\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m1.09652\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 583 | loss: 1.09652 - acc: 0.8746 -- iter: 31/31\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m1.08679\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 584 | loss: 1.08679 - acc: 0.8775 -- iter: 31/31\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m1.07766\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 585 | loss: 1.07766 - acc: 0.8801 -- iter: 31/31\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m1.06909\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 586 | loss: 1.06909 - acc: 0.8824 -- iter: 31/31\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m1.06100\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 587 | loss: 1.06100 - acc: 0.8845 -- iter: 31/31\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m1.05336\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 588 | loss: 1.05336 - acc: 0.8863 -- iter: 31/31\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m1.04611\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 589 | loss: 1.04611 - acc: 0.8880 -- iter: 31/31\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m1.03921\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 590 | loss: 1.03921 - acc: 0.8895 -- iter: 31/31\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m1.03264\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 591 | loss: 1.03264 - acc: 0.8909 -- iter: 31/31\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m1.02635\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 592 | loss: 1.02635 - acc: 0.8921 -- iter: 31/31\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m1.02032\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 593 | loss: 1.02032 - acc: 0.8933 -- iter: 31/31\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m1.01453\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 594 | loss: 1.01453 - acc: 0.8943 -- iter: 31/31\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m1.00894\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 595 | loss: 1.00894 - acc: 0.8951 -- iter: 31/31\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m1.29053\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 596 | loss: 1.29053 - acc: 0.8153 -- iter: 31/31\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m1.25676\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 597 | loss: 1.25676 - acc: 0.8241 -- iter: 31/31\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m1.22613\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 598 | loss: 1.22613 - acc: 0.8320 -- iter: 31/31\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m1.19831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 599 | loss: 1.19831 - acc: 0.8391 -- iter: 31/31\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m1.41786\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 600 | loss: 1.41786 - acc: 0.7681 -- iter: 31/31\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m1.37050\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 601 | loss: 1.37050 - acc: 0.7784 -- iter: 31/31\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m1.32772\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 602 | loss: 1.32772 - acc: 0.7877 -- iter: 31/31\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m1.28905\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 603 | loss: 1.28905 - acc: 0.7960 -- iter: 31/31\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m1.25405\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 604 | loss: 1.25405 - acc: 0.8035 -- iter: 31/31\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m1.22236\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 605 | loss: 1.22236 - acc: 0.8102 -- iter: 31/31\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m1.19361\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 606 | loss: 1.19361 - acc: 0.8163 -- iter: 31/31\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m1.16750\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 607 | loss: 1.16750 - acc: 0.8218 -- iter: 31/31\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m1.14376\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 608 | loss: 1.14376 - acc: 0.8267 -- iter: 31/31\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m1.12213\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 609 | loss: 1.12213 - acc: 0.8311 -- iter: 31/31\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m1.40658\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 610 | loss: 1.40658 - acc: 0.7577 -- iter: 31/31\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m1.35829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 611 | loss: 1.35829 - acc: 0.7690 -- iter: 31/31\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m1.31471\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 612 | loss: 1.31471 - acc: 0.7792 -- iter: 31/31\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m1.27532\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 613 | loss: 1.27532 - acc: 0.7884 -- iter: 31/31\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m1.23970\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 614 | loss: 1.23970 - acc: 0.7966 -- iter: 31/31\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m1.20746\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 615 | loss: 1.20746 - acc: 0.8041 -- iter: 31/31\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m1.17822\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 616 | loss: 1.17822 - acc: 0.8108 -- iter: 31/31\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m1.15169\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 617 | loss: 1.15169 - acc: 0.8168 -- iter: 31/31\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m1.12758\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 618 | loss: 1.12758 - acc: 0.8222 -- iter: 31/31\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m1.10562\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 619 | loss: 1.10562 - acc: 0.8271 -- iter: 31/31\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m1.08561\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 620 | loss: 1.08561 - acc: 0.8315 -- iter: 31/31\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m1.06732\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 621 | loss: 1.06732 - acc: 0.8354 -- iter: 31/31\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m1.05059\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 622 | loss: 1.05059 - acc: 0.8422 -- iter: 31/31\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m1.03525\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 623 | loss: 1.03525 - acc: 0.8483 -- iter: 31/31\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m1.02115\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 624 | loss: 1.02115 - acc: 0.8538 -- iter: 31/31\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m1.00817\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 625 | loss: 1.00817 - acc: 0.8587 -- iter: 31/31\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.99618\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 626 | loss: 0.99618 - acc: 0.8632 -- iter: 31/31\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.98509\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 627 | loss: 0.98509 - acc: 0.8672 -- iter: 31/31\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.97480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 628 | loss: 0.97480 - acc: 0.8708 -- iter: 31/31\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.96523\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 629 | loss: 0.96523 - acc: 0.8740 -- iter: 31/31\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m1.32938\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 630 | loss: 1.32938 - acc: 0.7963 -- iter: 31/31\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m1.28393\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 631 | loss: 1.28393 - acc: 0.8070 -- iter: 31/31\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m1.24288\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 632 | loss: 1.24288 - acc: 0.8166 -- iter: 31/31\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m1.20578\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 633 | loss: 1.20578 - acc: 0.8253 -- iter: 31/31\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m1.17221\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 634 | loss: 1.17221 - acc: 0.8331 -- iter: 31/31\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m1.14181\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 635 | loss: 1.14181 - acc: 0.8401 -- iter: 31/31\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m1.41761\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 636 | loss: 1.41761 - acc: 0.7658 -- iter: 31/31\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m1.36242\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 637 | loss: 1.36242 - acc: 0.7795 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m1.31268\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 638 | loss: 1.31268 - acc: 0.7919 -- iter: 31/31\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m1.26781\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 639 | loss: 1.26781 - acc: 0.8030 -- iter: 31/31\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m1.48608\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 640 | loss: 1.48608 - acc: 0.7388 -- iter: 31/31\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m1.42375\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 641 | loss: 1.42375 - acc: 0.7553 -- iter: 31/31\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m1.62543\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 642 | loss: 1.62543 - acc: 0.6991 -- iter: 31/31\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m1.54920\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 643 | loss: 1.54920 - acc: 0.7195 -- iter: 31/31\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m1.48063\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 644 | loss: 1.48063 - acc: 0.7379 -- iter: 31/31\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m1.41892\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 645 | loss: 1.41892 - acc: 0.7544 -- iter: 31/31\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m1.36334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 646 | loss: 1.36334 - acc: 0.7693 -- iter: 31/31\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m1.31326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 647 | loss: 1.31326 - acc: 0.7827 -- iter: 31/31\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m1.26810\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 648 | loss: 1.26810 - acc: 0.7947 -- iter: 31/31\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m1.22734\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 649 | loss: 1.22734 - acc: 0.8056 -- iter: 31/31\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m1.19052\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 650 | loss: 1.19052 - acc: 0.8154 -- iter: 31/31\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m1.15723\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 651 | loss: 1.15723 - acc: 0.8241 -- iter: 31/31\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m1.42527\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 652 | loss: 1.42527 - acc: 0.7514 -- iter: 31/31\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m1.36831\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 653 | loss: 1.36831 - acc: 0.7698 -- iter: 31/31\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m1.31699\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 654 | loss: 1.31699 - acc: 0.7864 -- iter: 31/31\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m1.27071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 655 | loss: 1.27071 - acc: 0.8013 -- iter: 31/31\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m1.22896\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 656 | loss: 1.22896 - acc: 0.8147 -- iter: 31/31\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m1.19125\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 657 | loss: 1.19125 - acc: 0.8268 -- iter: 31/31\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m1.15716\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 658 | loss: 1.15716 - acc: 0.8377 -- iter: 31/31\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m1.12631\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 659 | loss: 1.12631 - acc: 0.8474 -- iter: 31/31\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m1.09836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 660 | loss: 1.09836 - acc: 0.8562 -- iter: 31/31\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m1.07300\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 661 | loss: 1.07300 - acc: 0.8642 -- iter: 31/31\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m1.04997\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 662 | loss: 1.04997 - acc: 0.8713 -- iter: 31/31\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m1.02901\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 663 | loss: 1.02901 - acc: 0.8777 -- iter: 31/31\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m1.00991\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 664 | loss: 1.00991 - acc: 0.8835 -- iter: 31/31\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.99248\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 665 | loss: 0.99248 - acc: 0.8855 -- iter: 31/31\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.97653\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 666 | loss: 0.97653 - acc: 0.8905 -- iter: 31/31\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.96192\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 667 | loss: 0.96192 - acc: 0.8950 -- iter: 31/31\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.94851\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 668 | loss: 0.94851 - acc: 0.8990 -- iter: 31/31\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.93616\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 669 | loss: 0.93616 - acc: 0.9027 -- iter: 31/31\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.92478\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 670 | loss: 0.92478 - acc: 0.9060 -- iter: 31/31\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.91425\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 671 | loss: 0.91425 - acc: 0.9089 -- iter: 31/31\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.90449\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 672 | loss: 0.90449 - acc: 0.9116 -- iter: 31/31\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.89543\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 673 | loss: 0.89543 - acc: 0.9140 -- iter: 31/31\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.88698\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 674 | loss: 0.88698 - acc: 0.9161 -- iter: 31/31\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.87909\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 675 | loss: 0.87909 - acc: 0.9180 -- iter: 31/31\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m1.24145\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 676 | loss: 1.24145 - acc: 0.8359 -- iter: 31/31\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m1.19772\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 677 | loss: 1.19772 - acc: 0.8426 -- iter: 31/31\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m1.51220\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 678 | loss: 1.51220 - acc: 0.7616 -- iter: 31/31\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m1.44131\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 679 | loss: 1.44131 - acc: 0.7758 -- iter: 31/31\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m1.71737\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 680 | loss: 1.71737 - acc: 0.7143 -- iter: 31/31\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m1.62610\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 681 | loss: 1.62610 - acc: 0.7332 -- iter: 31/31\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m1.88682\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 682 | loss: 1.88682 - acc: 0.6792 -- iter: 31/31\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m1.77895\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 683 | loss: 1.77895 - acc: 0.7016 -- iter: 31/31\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m1.68205\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 684 | loss: 1.68205 - acc: 0.7218 -- iter: 31/31\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m1.59499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 685 | loss: 1.59499 - acc: 0.7399 -- iter: 31/31\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m1.51674\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 686 | loss: 1.51674 - acc: 0.7563 -- iter: 31/31\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m1.44637\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 687 | loss: 1.44637 - acc: 0.7710 -- iter: 31/31\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m1.38307\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 688 | loss: 1.38307 - acc: 0.7842 -- iter: 31/31\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m1.32609\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 689 | loss: 1.32609 - acc: 0.7961 -- iter: 31/31\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m1.56689\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 690 | loss: 1.56689 - acc: 0.7262 -- iter: 31/31\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m1.49158\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 691 | loss: 1.49158 - acc: 0.7439 -- iter: 31/31\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m1.42385\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 692 | loss: 1.42385 - acc: 0.7598 -- iter: 31/31\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m1.36291\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 693 | loss: 1.36291 - acc: 0.7741 -- iter: 31/31\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m1.30805\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 694 | loss: 1.30805 - acc: 0.7871 -- iter: 31/31\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m1.25862\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 695 | loss: 1.25862 - acc: 0.7987 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m1.21406\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 696 | loss: 1.21406 - acc: 0.8091 -- iter: 31/31\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m1.17384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 697 | loss: 1.17384 - acc: 0.8185 -- iter: 31/31\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m1.13752\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 698 | loss: 1.13752 - acc: 0.8270 -- iter: 31/31\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m1.10469\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 699 | loss: 1.10469 - acc: 0.8346 -- iter: 31/31\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m1.07497\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 700 | loss: 1.07497 - acc: 0.8415 -- iter: 31/31\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m1.04803\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 701 | loss: 1.04803 - acc: 0.8477 -- iter: 31/31\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m1.25955\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 702 | loss: 1.25955 - acc: 0.7855 -- iter: 31/31\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m1.21388\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 703 | loss: 1.21388 - acc: 0.7973 -- iter: 31/31\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m1.17266\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 704 | loss: 1.17266 - acc: 0.8078 -- iter: 31/31\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m1.13544\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 705 | loss: 1.13544 - acc: 0.8174 -- iter: 31/31\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m1.10179\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 706 | loss: 1.10179 - acc: 0.8260 -- iter: 31/31\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m1.07133\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 707 | loss: 1.07133 - acc: 0.8337 -- iter: 31/31\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m1.35388\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 708 | loss: 1.35388 - acc: 0.7632 -- iter: 31/31\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m1.29800\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 709 | loss: 1.29800 - acc: 0.7772 -- iter: 31/31\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m1.24763\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 710 | loss: 1.24763 - acc: 0.7898 -- iter: 31/31\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m1.20222\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 711 | loss: 1.20222 - acc: 0.8012 -- iter: 31/31\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m1.16123\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 712 | loss: 1.16123 - acc: 0.8114 -- iter: 31/31\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m1.12420\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 713 | loss: 1.12420 - acc: 0.8206 -- iter: 31/31\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m1.09072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 714 | loss: 1.09072 - acc: 0.8288 -- iter: 31/31\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m1.06043\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 715 | loss: 1.06043 - acc: 0.8363 -- iter: 31/31\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m1.03297\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 716 | loss: 1.03297 - acc: 0.8430 -- iter: 31/31\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m1.00807\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 717 | loss: 1.00807 - acc: 0.8490 -- iter: 31/31\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.98544\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 718 | loss: 0.98544 - acc: 0.8544 -- iter: 31/31\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.96486\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 719 | loss: 0.96486 - acc: 0.8593 -- iter: 31/31\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.94611\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 720 | loss: 0.94611 - acc: 0.8637 -- iter: 31/31\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.92900\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 721 | loss: 0.92900 - acc: 0.8676 -- iter: 31/31\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.91336\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 722 | loss: 0.91336 - acc: 0.8712 -- iter: 31/31\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.89904\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 723 | loss: 0.89904 - acc: 0.8744 -- iter: 31/31\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.88589\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 724 | loss: 0.88589 - acc: 0.8773 -- iter: 31/31\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.87380\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 725 | loss: 0.87380 - acc: 0.8799 -- iter: 31/31\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.86266\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 726 | loss: 0.86266 - acc: 0.8822 -- iter: 31/31\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.85237\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 727 | loss: 0.85237 - acc: 0.8843 -- iter: 31/31\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.84284\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 728 | loss: 0.84284 - acc: 0.8862 -- iter: 31/31\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.83400\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 729 | loss: 0.83400 - acc: 0.8879 -- iter: 31/31\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.82578\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 730 | loss: 0.82578 - acc: 0.8894 -- iter: 31/31\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.81810\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 731 | loss: 0.81810 - acc: 0.8908 -- iter: 31/31\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m1.19113\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 732 | loss: 1.19113 - acc: 0.8146 -- iter: 31/31\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m1.14656\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 733 | loss: 1.14656 - acc: 0.8235 -- iter: 31/31\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m1.10633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 734 | loss: 1.10633 - acc: 0.8315 -- iter: 31/31\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m1.06999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 735 | loss: 1.06999 - acc: 0.8386 -- iter: 31/31\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m1.33617\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 736 | loss: 1.33617 - acc: 0.7709 -- iter: 31/31\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m1.27669\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 737 | loss: 1.27669 - acc: 0.7841 -- iter: 31/31\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m1.57682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 738 | loss: 1.57682 - acc: 0.7122 -- iter: 31/31\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m1.49335\u001b[0m\u001b[0m | time: 0.011s\n",
      "| Adam | epoch: 739 | loss: 1.49335 - acc: 0.7313 -- iter: 31/31\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m1.41830\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 740 | loss: 1.41830 - acc: 0.7485 -- iter: 31/31\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m1.35078\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 741 | loss: 1.35078 - acc: 0.7640 -- iter: 31/31\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m1.29003\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 742 | loss: 1.29003 - acc: 0.7779 -- iter: 31/31\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m1.23532\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 743 | loss: 1.23532 - acc: 0.7904 -- iter: 31/31\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m1.18603\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 744 | loss: 1.18603 - acc: 0.8017 -- iter: 31/31\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m1.14160\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 745 | loss: 1.14160 - acc: 0.8118 -- iter: 31/31\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m1.10152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 746 | loss: 1.10152 - acc: 0.8210 -- iter: 31/31\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m1.06533\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 747 | loss: 1.06533 - acc: 0.8292 -- iter: 31/31\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m1.35716\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 748 | loss: 1.35716 - acc: 0.7592 -- iter: 31/31\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m1.29528\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 749 | loss: 1.29528 - acc: 0.7736 -- iter: 31/31\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m1.60305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 750 | loss: 1.60305 - acc: 0.7091 -- iter: 31/31\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m1.51668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 751 | loss: 1.51668 - acc: 0.7285 -- iter: 31/31\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m1.43904\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 752 | loss: 1.43904 - acc: 0.7460 -- iter: 31/31\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m1.36921\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 753 | loss: 1.36921 - acc: 0.7617 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m1.30639\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 754 | loss: 1.30639 - acc: 0.7759 -- iter: 31/31\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m1.24983\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 755 | loss: 1.24983 - acc: 0.7886 -- iter: 31/31\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m1.63037\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 756 | loss: 1.63037 - acc: 0.7130 -- iter: 31/31\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m1.54152\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 757 | loss: 1.54152 - acc: 0.7320 -- iter: 31/31\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m1.46165\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 758 | loss: 1.46165 - acc: 0.7491 -- iter: 31/31\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m1.38983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 759 | loss: 1.38983 - acc: 0.7645 -- iter: 31/31\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m1.56455\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 760 | loss: 1.56455 - acc: 0.7107 -- iter: 31/31\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m1.48256\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 761 | loss: 1.48256 - acc: 0.7299 -- iter: 31/31\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m1.40884\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 762 | loss: 1.40884 - acc: 0.7473 -- iter: 31/31\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m1.34252\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 763 | loss: 1.34252 - acc: 0.7628 -- iter: 31/31\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m1.28282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 764 | loss: 1.28282 - acc: 0.7769 -- iter: 31/31\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m1.22906\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 765 | loss: 1.22906 - acc: 0.7895 -- iter: 31/31\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m1.18060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 766 | loss: 1.18060 - acc: 0.8009 -- iter: 31/31\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m1.13691\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 767 | loss: 1.13691 - acc: 0.8111 -- iter: 31/31\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m1.09747\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 768 | loss: 1.09747 - acc: 0.8203 -- iter: 31/31\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m1.06184\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 769 | loss: 1.06184 - acc: 0.8286 -- iter: 31/31\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m1.02962\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 770 | loss: 1.02962 - acc: 0.8361 -- iter: 31/31\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m1.00046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 771 | loss: 1.00046 - acc: 0.8428 -- iter: 31/31\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m1.32659\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 772 | loss: 1.32659 - acc: 0.7682 -- iter: 31/31\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m1.26755\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 773 | loss: 1.26755 - acc: 0.7817 -- iter: 31/31\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m1.21438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 774 | loss: 1.21438 - acc: 0.7939 -- iter: 31/31\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m1.16647\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 775 | loss: 1.16647 - acc: 0.8048 -- iter: 31/31\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m1.12327\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 776 | loss: 1.12327 - acc: 0.8146 -- iter: 31/31\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m1.08427\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 777 | loss: 1.08427 - acc: 0.8235 -- iter: 31/31\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m1.33999\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 778 | loss: 1.33999 - acc: 0.7508 -- iter: 31/31\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m1.27920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 779 | loss: 1.27920 - acc: 0.7661 -- iter: 31/31\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m1.22445\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 780 | loss: 1.22445 - acc: 0.7798 -- iter: 31/31\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m1.17512\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 781 | loss: 1.17512 - acc: 0.7921 -- iter: 31/31\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m1.45150\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 782 | loss: 1.45150 - acc: 0.7226 -- iter: 31/31\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m1.37943\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 783 | loss: 1.37943 - acc: 0.7407 -- iter: 31/31\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m1.60306\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 784 | loss: 1.60306 - acc: 0.6795 -- iter: 31/31\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m1.51596\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 785 | loss: 1.51596 - acc: 0.7019 -- iter: 31/31\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m1.71157\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 786 | loss: 1.71157 - acc: 0.6478 -- iter: 31/31\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m1.61388\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 787 | loss: 1.61388 - acc: 0.6733 -- iter: 31/31\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m1.84309\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 788 | loss: 1.84309 - acc: 0.6189 -- iter: 31/31\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m1.73263\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 789 | loss: 1.73263 - acc: 0.6473 -- iter: 31/31\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m1.63342\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 790 | loss: 1.63342 - acc: 0.6729 -- iter: 31/31\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m1.54428\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 791 | loss: 1.54428 - acc: 0.6960 -- iter: 31/31\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m1.46415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 792 | loss: 1.46415 - acc: 0.7167 -- iter: 31/31\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m1.39210\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 793 | loss: 1.39210 - acc: 0.7353 -- iter: 31/31\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m1.65537\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 794 | loss: 1.65537 - acc: 0.6650 -- iter: 31/31\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m1.56438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 795 | loss: 1.56438 - acc: 0.6889 -- iter: 31/31\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m1.80586\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 796 | loss: 1.80586 - acc: 0.6232 -- iter: 31/31\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m1.70017\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 797 | loss: 1.70017 - acc: 0.6512 -- iter: 31/31\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m1.60523\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 798 | loss: 1.60523 - acc: 0.6764 -- iter: 31/31\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m1.51991\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 799 | loss: 1.51991 - acc: 0.6991 -- iter: 31/31\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m1.44322\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 800 | loss: 1.44322 - acc: 0.7195 -- iter: 31/31\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m1.37424\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 801 | loss: 1.37424 - acc: 0.7379 -- iter: 31/31\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m1.31216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 802 | loss: 1.31216 - acc: 0.7544 -- iter: 31/31\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m1.25626\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 803 | loss: 1.25626 - acc: 0.7693 -- iter: 31/31\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m1.20588\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 804 | loss: 1.20588 - acc: 0.7827 -- iter: 31/31\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m1.16045\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 805 | loss: 1.16045 - acc: 0.7947 -- iter: 31/31\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m1.11945\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 806 | loss: 1.11945 - acc: 0.8056 -- iter: 31/31\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m1.08241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 807 | loss: 1.08241 - acc: 0.8153 -- iter: 31/31\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m1.04891\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 808 | loss: 1.04891 - acc: 0.8241 -- iter: 31/31\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m1.01858\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 809 | loss: 1.01858 - acc: 0.8320 -- iter: 31/31\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m1.28472\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 810 | loss: 1.28472 - acc: 0.7714 -- iter: 31/31\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m1.23057\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 811 | loss: 1.23057 - acc: 0.7846 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m1.18175\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 812 | loss: 1.18175 - acc: 0.7965 -- iter: 31/31\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m1.13771\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 813 | loss: 1.13771 - acc: 0.8071 -- iter: 31/31\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m1.43789\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 814 | loss: 1.43789 - acc: 0.7329 -- iter: 31/31\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m1.36815\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 815 | loss: 1.36815 - acc: 0.7499 -- iter: 31/31\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m1.58061\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 816 | loss: 1.58061 - acc: 0.6878 -- iter: 31/31\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m1.49671\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 817 | loss: 1.49671 - acc: 0.7094 -- iter: 31/31\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m1.42127\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 818 | loss: 1.42127 - acc: 0.7288 -- iter: 31/31\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m1.35340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 819 | loss: 1.35340 - acc: 0.7462 -- iter: 31/31\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m1.55945\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 820 | loss: 1.55945 - acc: 0.6877 -- iter: 31/31\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m1.47786\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 821 | loss: 1.47786 - acc: 0.7093 -- iter: 31/31\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m1.40448\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 822 | loss: 1.40448 - acc: 0.7287 -- iter: 31/31\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m1.33847\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 823 | loss: 1.33847 - acc: 0.7461 -- iter: 31/31\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m1.27904\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 824 | loss: 1.27904 - acc: 0.7618 -- iter: 31/31\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m1.22550\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 825 | loss: 1.22550 - acc: 0.7760 -- iter: 31/31\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m1.43441\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 826 | loss: 1.43441 - acc: 0.7080 -- iter: 31/31\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m1.36530\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 827 | loss: 1.36530 - acc: 0.7276 -- iter: 31/31\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m1.30310\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 828 | loss: 1.30310 - acc: 0.7451 -- iter: 31/31\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m1.24708\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 829 | loss: 1.24708 - acc: 0.7609 -- iter: 31/31\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m1.19660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 830 | loss: 1.19660 - acc: 0.7752 -- iter: 31/31\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m1.15108\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 831 | loss: 1.15108 - acc: 0.7880 -- iter: 31/31\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m1.11000\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 832 | loss: 1.11000 - acc: 0.7995 -- iter: 31/31\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m1.07288\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 833 | loss: 1.07288 - acc: 0.8099 -- iter: 31/31\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m1.03933\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 834 | loss: 1.03933 - acc: 0.8192 -- iter: 31/31\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m1.00896\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 835 | loss: 1.00896 - acc: 0.8276 -- iter: 31/31\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m1.25008\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 836 | loss: 1.25008 - acc: 0.7578 -- iter: 31/31\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m1.19838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 837 | loss: 1.19838 - acc: 0.7723 -- iter: 31/31\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m1.15175\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 838 | loss: 1.15175 - acc: 0.7854 -- iter: 31/31\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m1.10968\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 839 | loss: 1.10968 - acc: 0.7972 -- iter: 31/31\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m1.07168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 840 | loss: 1.07168 - acc: 0.8078 -- iter: 31/31\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m1.03732\u001b[0m\u001b[0m | time: 0.010s\n",
      "| Adam | epoch: 841 | loss: 1.03732 - acc: 0.8173 -- iter: 31/31\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m1.00624\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 842 | loss: 1.00624 - acc: 0.8259 -- iter: 31/31\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.97808\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 843 | loss: 0.97808 - acc: 0.8336 -- iter: 31/31\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m1.23267\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 844 | loss: 1.23267 - acc: 0.7664 -- iter: 31/31\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m1.18162\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 845 | loss: 1.18162 - acc: 0.7801 -- iter: 31/31\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m1.13558\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 846 | loss: 1.13558 - acc: 0.7924 -- iter: 31/31\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m1.09405\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 847 | loss: 1.09405 - acc: 0.8035 -- iter: 31/31\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m1.41235\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 848 | loss: 1.41235 - acc: 0.7296 -- iter: 31/31\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m1.34305\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 849 | loss: 1.34305 - acc: 0.7470 -- iter: 31/31\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m1.59054\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 850 | loss: 1.59054 - acc: 0.6852 -- iter: 31/31\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m1.50354\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 851 | loss: 1.50354 - acc: 0.7070 -- iter: 31/31\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m1.42532\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 852 | loss: 1.42532 - acc: 0.7266 -- iter: 31/31\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m1.35496\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 853 | loss: 1.35496 - acc: 0.7443 -- iter: 31/31\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m1.29165\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 854 | loss: 1.29165 - acc: 0.7602 -- iter: 31/31\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m1.23464\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 855 | loss: 1.23464 - acc: 0.7745 -- iter: 31/31\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m1.18329\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 856 | loss: 1.18329 - acc: 0.7873 -- iter: 31/31\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m1.13699\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 857 | loss: 1.13699 - acc: 0.7989 -- iter: 31/31\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m1.09522\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 858 | loss: 1.09522 - acc: 0.8094 -- iter: 31/31\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m1.05751\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 859 | loss: 1.05751 - acc: 0.8187 -- iter: 31/31\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m1.02344\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 860 | loss: 1.02344 - acc: 0.8272 -- iter: 31/31\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.99262\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 861 | loss: 0.99262 - acc: 0.8348 -- iter: 31/31\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.96471\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 862 | loss: 0.96471 - acc: 0.8416 -- iter: 31/31\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.93941\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 863 | loss: 0.93941 - acc: 0.8478 -- iter: 31/31\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.91646\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 864 | loss: 0.91646 - acc: 0.8533 -- iter: 31/31\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.89559\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 865 | loss: 0.89559 - acc: 0.8583 -- iter: 31/31\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.87661\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 866 | loss: 0.87661 - acc: 0.8628 -- iter: 31/31\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.85931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 867 | loss: 0.85931 - acc: 0.8669 -- iter: 31/31\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.84352\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 868 | loss: 0.84352 - acc: 0.8705 -- iter: 31/31\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.82908\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 869 | loss: 0.82908 - acc: 0.8738 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m1.23918\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 870 | loss: 1.23918 - acc: 0.7928 -- iter: 31/31\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m1.18491\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 871 | loss: 1.18491 - acc: 0.8039 -- iter: 31/31\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m1.13600\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 872 | loss: 1.13600 - acc: 0.8138 -- iter: 31/31\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m1.09191\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 873 | loss: 1.09191 - acc: 0.8228 -- iter: 31/31\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m1.05213\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 874 | loss: 1.05213 - acc: 0.8308 -- iter: 31/31\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m1.01622\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 875 | loss: 1.01622 - acc: 0.8380 -- iter: 31/31\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.98376\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 876 | loss: 0.98376 - acc: 0.8446 -- iter: 31/31\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.95440\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 877 | loss: 0.95440 - acc: 0.8504 -- iter: 31/31\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.92782\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 878 | loss: 0.92782 - acc: 0.8557 -- iter: 31/31\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.90372\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 879 | loss: 0.90372 - acc: 0.8605 -- iter: 31/31\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m1.20168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 880 | loss: 1.20168 - acc: 0.7938 -- iter: 31/31\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m1.14999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 881 | loss: 1.14999 - acc: 0.8047 -- iter: 31/31\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m1.10342\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 882 | loss: 1.10342 - acc: 0.8146 -- iter: 31/31\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m1.06142\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 883 | loss: 1.06142 - acc: 0.8234 -- iter: 31/31\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m1.02353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 884 | loss: 1.02353 - acc: 0.8314 -- iter: 31/31\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.98931\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 885 | loss: 0.98931 - acc: 0.8386 -- iter: 31/31\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m1.26559\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 886 | loss: 1.26559 - acc: 0.7709 -- iter: 31/31\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m1.20703\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 887 | loss: 1.20703 - acc: 0.7841 -- iter: 31/31\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m1.15429\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 888 | loss: 1.15429 - acc: 0.7960 -- iter: 31/31\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m1.10677\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 889 | loss: 1.10677 - acc: 0.8067 -- iter: 31/31\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m1.06392\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 890 | loss: 1.06392 - acc: 0.8164 -- iter: 31/31\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m1.02526\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 891 | loss: 1.02526 - acc: 0.8251 -- iter: 31/31\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.99036\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 892 | loss: 0.99036 - acc: 0.8329 -- iter: 31/31\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.95881\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 893 | loss: 0.95881 - acc: 0.8399 -- iter: 31/31\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.93028\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 894 | loss: 0.93028 - acc: 0.8462 -- iter: 31/31\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.90444\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 895 | loss: 0.90444 - acc: 0.8519 -- iter: 31/31\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m1.18752\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 896 | loss: 1.18752 - acc: 0.7732 -- iter: 31/31\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m1.13575\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 897 | loss: 1.13575 - acc: 0.7862 -- iter: 31/31\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m1.08909\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 898 | loss: 1.08909 - acc: 0.7979 -- iter: 31/31\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m1.04701\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 899 | loss: 1.04701 - acc: 0.8084 -- iter: 31/31\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m1.38605\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 900 | loss: 1.38605 - acc: 0.7437 -- iter: 31/31\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m1.31422\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 901 | loss: 1.31422 - acc: 0.7597 -- iter: 31/31\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m1.24960\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 902 | loss: 1.24960 - acc: 0.7740 -- iter: 31/31\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m1.19145\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 903 | loss: 1.19145 - acc: 0.7869 -- iter: 31/31\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m1.13907\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 904 | loss: 1.13907 - acc: 0.7986 -- iter: 31/31\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m1.09189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 905 | loss: 1.09189 - acc: 0.8090 -- iter: 31/31\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m1.04935\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 906 | loss: 1.04935 - acc: 0.8185 -- iter: 31/31\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m1.01097\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 907 | loss: 1.01097 - acc: 0.8269 -- iter: 31/31\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.97632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 908 | loss: 0.97632 - acc: 0.8346 -- iter: 31/31\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.94502\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 909 | loss: 0.94502 - acc: 0.8414 -- iter: 31/31\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.91670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 910 | loss: 0.91670 - acc: 0.8476 -- iter: 31/31\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.89107\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 911 | loss: 0.89107 - acc: 0.8532 -- iter: 31/31\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.86784\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 912 | loss: 0.86784 - acc: 0.8582 -- iter: 31/31\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.84676\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 913 | loss: 0.84676 - acc: 0.8627 -- iter: 31/31\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.82762\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 914 | loss: 0.82762 - acc: 0.8667 -- iter: 31/31\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.81020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 915 | loss: 0.81020 - acc: 0.8704 -- iter: 31/31\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.79433\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 916 | loss: 0.79433 - acc: 0.8737 -- iter: 31/31\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.77985\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 917 | loss: 0.77985 - acc: 0.8766 -- iter: 31/31\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.76661\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 918 | loss: 0.76661 - acc: 0.8793 -- iter: 31/31\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.75449\u001b[0m\u001b[0m | time: 0.006s\n",
      "| Adam | epoch: 919 | loss: 0.75449 - acc: 0.8817 -- iter: 31/31\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.74337\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 920 | loss: 0.74337 - acc: 0.8838 -- iter: 31/31\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.73315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 921 | loss: 0.73315 - acc: 0.8858 -- iter: 31/31\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m1.01674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 922 | loss: 1.01674 - acc: 0.8133 -- iter: 31/31\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.97886\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 923 | loss: 0.97886 - acc: 0.8223 -- iter: 31/31\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.94466\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 924 | loss: 0.94466 - acc: 0.8304 -- iter: 31/31\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.91376\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 925 | loss: 0.91376 - acc: 0.8377 -- iter: 31/31\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.88581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 926 | loss: 0.88581 - acc: 0.8442 -- iter: 31/31\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.86050\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 927 | loss: 0.86050 - acc: 0.8501 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.83757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 928 | loss: 0.83757 - acc: 0.8554 -- iter: 31/31\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.81677\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 929 | loss: 0.81677 - acc: 0.8602 -- iter: 31/31\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.79787\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 930 | loss: 0.79787 - acc: 0.8645 -- iter: 31/31\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.78069\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 931 | loss: 0.78069 - acc: 0.8684 -- iter: 31/31\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.76505\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 932 | loss: 0.76505 - acc: 0.8719 -- iter: 31/31\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.75079\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 933 | loss: 0.75079 - acc: 0.8750 -- iter: 31/31\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m1.08977\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 934 | loss: 1.08977 - acc: 0.8069 -- iter: 31/31\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m1.04279\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 935 | loss: 1.04279 - acc: 0.8165 -- iter: 31/31\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m1.00044\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 936 | loss: 1.00044 - acc: 0.8252 -- iter: 31/31\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.96223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 937 | loss: 0.96223 - acc: 0.8330 -- iter: 31/31\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.92775\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 938 | loss: 0.92775 - acc: 0.8400 -- iter: 31/31\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.89660\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 939 | loss: 0.89660 - acc: 0.8463 -- iter: 31/31\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.86844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 940 | loss: 0.86844 - acc: 0.8520 -- iter: 31/31\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.84297\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 941 | loss: 0.84297 - acc: 0.8571 -- iter: 31/31\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.81990\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 942 | loss: 0.81990 - acc: 0.8617 -- iter: 31/31\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.79898\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 943 | loss: 0.79898 - acc: 0.8659 -- iter: 31/31\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.78000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 944 | loss: 0.78000 - acc: 0.8696 -- iter: 31/31\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.76275\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 945 | loss: 0.76275 - acc: 0.8730 -- iter: 31/31\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.74706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 946 | loss: 0.74706 - acc: 0.8760 -- iter: 31/31\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.73277\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 947 | loss: 0.73277 - acc: 0.8787 -- iter: 31/31\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.71972\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 948 | loss: 0.71972 - acc: 0.8812 -- iter: 31/31\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.70780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 949 | loss: 0.70780 - acc: 0.8834 -- iter: 31/31\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.69688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 950 | loss: 0.69688 - acc: 0.8854 -- iter: 31/31\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.68687\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 951 | loss: 0.68687 - acc: 0.8872 -- iter: 31/31\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.67767\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 952 | loss: 0.67767 - acc: 0.8888 -- iter: 31/31\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.66919\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 953 | loss: 0.66919 - acc: 0.8902 -- iter: 31/31\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.66137\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 954 | loss: 0.66137 - acc: 0.8915 -- iter: 31/31\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.65414\u001b[0m\u001b[0m | time: 0.007s\n",
      "| Adam | epoch: 955 | loss: 0.65414 - acc: 0.8927 -- iter: 31/31\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m1.07802\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 956 | loss: 1.07802 - acc: 0.8099 -- iter: 31/31\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m1.02889\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 957 | loss: 1.02889 - acc: 0.8192 -- iter: 31/31\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m1.45474\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 958 | loss: 1.45474 - acc: 0.7437 -- iter: 31/31\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m1.36799\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 959 | loss: 1.36799 - acc: 0.7597 -- iter: 31/31\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m1.28998\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 960 | loss: 1.28998 - acc: 0.7740 -- iter: 31/31\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m1.21983\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 961 | loss: 1.21983 - acc: 0.7870 -- iter: 31/31\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m1.15671\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 962 | loss: 1.15671 - acc: 0.7986 -- iter: 31/31\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m1.09991\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 963 | loss: 1.09991 - acc: 0.8090 -- iter: 31/31\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m1.42577\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 964 | loss: 1.42577 - acc: 0.7378 -- iter: 31/31\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m1.34214\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 965 | loss: 1.34214 - acc: 0.7544 -- iter: 31/31\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m1.26695\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 966 | loss: 1.26695 - acc: 0.7692 -- iter: 31/31\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m1.19932\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 967 | loss: 1.19932 - acc: 0.7826 -- iter: 31/31\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m1.13847\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 968 | loss: 1.13847 - acc: 0.7947 -- iter: 31/31\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m1.08371\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 969 | loss: 1.08371 - acc: 0.8056 -- iter: 31/31\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m1.03439\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 970 | loss: 1.03439 - acc: 0.8153 -- iter: 31/31\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.98996\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 971 | loss: 0.98996 - acc: 0.8241 -- iter: 31/31\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m1.31591\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 972 | loss: 1.31591 - acc: 0.7546 -- iter: 31/31\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m1.24332\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 973 | loss: 1.24332 - acc: 0.7695 -- iter: 31/31\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m1.57194\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 974 | loss: 1.57194 - acc: 0.6957 -- iter: 31/31\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m1.47395\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 975 | loss: 1.47395 - acc: 0.7165 -- iter: 31/31\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m1.71536\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 976 | loss: 1.71536 - acc: 0.6610 -- iter: 31/31\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m1.60337\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 977 | loss: 1.60337 - acc: 0.6852 -- iter: 31/31\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m1.50275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 978 | loss: 1.50275 - acc: 0.7070 -- iter: 31/31\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m1.41234\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 979 | loss: 1.41234 - acc: 0.7266 -- iter: 31/31\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m1.58392\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 980 | loss: 1.58392 - acc: 0.6733 -- iter: 31/31\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m1.48565\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 981 | loss: 1.48565 - acc: 0.6963 -- iter: 31/31\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m1.74132\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 982 | loss: 1.74132 - acc: 0.6396 -- iter: 31/31\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m1.62766\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 983 | loss: 1.62766 - acc: 0.6659 -- iter: 31/31\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m1.52556\u001b[0m\u001b[0m | time: 0.005s\n",
      "| Adam | epoch: 984 | loss: 1.52556 - acc: 0.6897 -- iter: 31/31\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m1.43379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 985 | loss: 1.43379 - acc: 0.7110 -- iter: 31/31\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m1.35131\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 986 | loss: 1.35131 - acc: 0.7302 -- iter: 31/31\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m1.27714\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 987 | loss: 1.27714 - acc: 0.7475 -- iter: 31/31\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m1.21041\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 988 | loss: 1.21041 - acc: 0.7631 -- iter: 31/31\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m1.15036\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 989 | loss: 1.15036 - acc: 0.7771 -- iter: 31/31\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m1.49069\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 990 | loss: 1.49069 - acc: 0.7059 -- iter: 31/31\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m1.40270\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 991 | loss: 1.40270 - acc: 0.7256 -- iter: 31/31\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m1.32359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 992 | loss: 1.32359 - acc: 0.7434 -- iter: 31/31\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m1.25244\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 993 | loss: 1.25244 - acc: 0.7593 -- iter: 31/31\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m1.18841\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 994 | loss: 1.18841 - acc: 0.7737 -- iter: 31/31\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m1.13078\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 995 | loss: 1.13078 - acc: 0.7867 -- iter: 31/31\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m1.07886\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 996 | loss: 1.07886 - acc: 0.7983 -- iter: 31/31\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m1.03208\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 997 | loss: 1.03208 - acc: 0.8088 -- iter: 31/31\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m1.38571\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 998 | loss: 1.38571 - acc: 0.7279 -- iter: 31/31\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m1.30823\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 999 | loss: 1.30823 - acc: 0.7455 -- iter: 31/31\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m1.23853\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 1000 | loss: 1.23853 - acc: 0.7612 -- iter: 31/31\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\user\\dharna mam Deep Learning\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.fit(training,output,n_epoch=1000,show_metric=True)\n",
    "model.save(\"model.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c544e3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.Get some input from user\\n2.convert ti bag of words\\n3.get a prediction from model\\n4.find the most probable class\\n5.pick a response from that class \\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1.Get some input from user\n",
    "2.convert ti bag of words\n",
    "3.get a prediction from model\n",
    "4.find the most probable class\n",
    "5.pick a response from that class \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca933a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words): #s is sentence input by user\n",
    "    bag=[0 for i in range(len(words))] #initially all will be zero\n",
    "    s_words=nltk.word_tokenize(s)\n",
    "    s_words=[stemmer.stem(word.lower()) for word in s_words]\n",
    "    for se in s_words:\n",
    "        for j,w, in enumerate(words):\n",
    "            if w==se:\n",
    "                bag[j]=1\n",
    "    return np.array(bag)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44247685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def chat():\n",
    "    while True:\n",
    "        inp=input(\"You:\")\n",
    "        if inp.lower()==\"quit\":\n",
    "            break\n",
    "        results=model.predict([bag_of_words(inp,words)])\n",
    "        results_index=np.argmax(results)\n",
    "        tag=labels[results_index]\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg[\"tag\"]==tag:\n",
    "                responses=tg[\"responses\"]\n",
    "        print(random.choice(responses))    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ffc5cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:Hello\n",
      "You can check various delicacies given in the food menu at www.mymenu.com\n",
      "You:What is your location?\n",
      "Our speciality for today is Chicken Tikka\n",
      "You:Hi\n",
      "Our Address is: 1000 Bridge Avenue, London EC3N 4AJ, UK\n",
      "You:What is your menu for today?\n",
      "Today's special is Chicken Tikka\n",
      "You:quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06269031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
